{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, deploy and review ML algorithm/model DFbVIF (dynamic factor based volatility index forecast model) from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of the algorithm\n",
    "  \n",
    "The [dynamic factor based volatility index forecast (DFbVIF) model](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?), is to make multi-step forecasts of multiple volatility indexes, as well as dynamic volatility attributions.\n",
    "  \n",
    "Widely watched, reported and utilized volatility indexes include VIX and others published by [CBOE](https://www.cboe.com/), such as VIX (on S&P 500), VXD (on DJIA), VXN (on Nasdaq 100), RVX (on Russel 2000), VXEEM (on emerging market), VXEWZ (on Brazil ETF), GVZ (on gold), OVX (on crude oil), EVZ (on Euro), VXAZN (on Amazon), VXAPL (on Apple), VXGS (on Goldman Sachs), VXGOG (on Google), VXIBM (on IBM), etc.\n",
    "  \n",
    "Volatility indexes published by global financial exchanges are regarded as among crucial indicators by many economy and market participants all over the world. Well-established holistic data-driven models able to analyze and forecast volatility indexes could serve as important tools.\n",
    "  \n",
    "Many volatility indexes, all price time-series underlying these volatility indexes, and many other relevant financial time-series are \"dynamically correlated\", i.e. correlated over time and cross-sectionally. A set of \"dominant dynamic correlation characteristics\" of these large number of time-series can be extracted by widely utilized dynamic factor models (DFMs). Those \"other relevant time-series\" are information-enhancing inputs of the models. Dynamic relationships summarized by dominant dynamic factors are less likely contaminated by random noises and, as a result, more likely to make more robust forecasts.\n",
    "  \n",
    "The DFbVIF model applies dynamic factor model (DFM) volatility analysis, [DFVCM](https://aws.amazon.com/marketplace/pp/prodview-yvaulquatt3v2?) algorithm, on DFM-input time-series, which are multiple time-series including both price time-series underlying the volatility indexes and other information-enhancing time-series. Then, the volatility forecasts of the underlying time-series are transformed into multi-step forecasts of the multiple volatility indexes.\n",
    "  \n",
    "Current version of the [DFbVIF](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?) algorithm offers two transformations for volatility index forecasts and associated dynamic volatility attributions: (1) UVF method (underlying volatility forecasts as predictors) and (2) QAR method (quadratic autoregressive forecasts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Academic publications on multi-step forecasts and multivariate volatilities with dynamic factor models\n",
    "  \n",
    "L. Alessi, M. Barigozzi and M. Capasso  (2007).  \"Dynamic factor GARCH: Multivariate volatility forecast for a large number of series\".  LEM Working Paper Series, No. 2006/25, Laboratory of Economics and Management (LEM), Pisa.\n",
    "  \n",
    "C. Doz  and  P. Fuleky  (2020).  \"Chapter 2,  Dynamic Factor Models\" in Macroeconomic Forecasting in the Era of Big Data: Theory and Practice, Ed. P. Fuleky,  Advanced Studies in Theoretical and Applied Econometrics, Volume 52.  Springer.  \n",
    "  \n",
    "i4cast LLC  (2025).  \"Introduction to Multi-step DFM-based Forecasts of Multiple Volatility Indexes\".  https://github.com/i4cast/aws/blob/main/dfm-based_volatility_index_forecast_model/publication/multi-step_DFM-based_forecasts_of_multiple_volatility_indexes.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook\n",
    "\n",
    "This sample notebook shows you how to train, tune, deploy and understand a custom ML algorithm/model: [Dynamic factor based volatility index forecast (DFbVIF)](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?), guided by common practices to [Use Algorithm and Model Package Resources](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-buy.html).\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    1. or your AWS account has a subscription to  [Dynamic factor based volatility index forecast (DFbVIF) model](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "    1. [Subscription](#1.1.-Subscription)\n",
    "    1. [Prepare relevant environment](#1.2.-Prepare-relevant-environment)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "    1. [Dataset format expected by the algorithm](#2.1.-Dataset-format-expected-by-the-algorithm)\n",
    "    1. [Configure and visualize training dataset](#2.2.-Configure-and-visualize-training-dataset)\n",
    "    1. [Upload datasets to Amazon S3](#2.3.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3.-Train-a-machine-learning-model)\n",
    "    1. [Set hyperparameters](#3.1.-Set-hyperparameters)\n",
    "    1. [Train a model](#3.2.-Train-a-model)\n",
    "1. [Tune your model (optional)](#4.-Tune-your-model-(optional))\n",
    "    1. [Tuning Guidelines](#4.1.-Tuning-guidelines)\n",
    "    1. [Define Tuning configuration](#4.2.-Define-tuning-configuration)\n",
    "    1. [Run a model tuning job](#4.3.-Run-a-model-tuning-job)\n",
    "1. [Deploy model and verify results](#5.-Deploy-model-and-verify-results)\n",
    "    1. [Trained or tuned model](#5.1.-Trained-or-tuned-model)\n",
    "    1. [Deploy trained or tuned model](#5.2.-Deploy-trained-or-tuned-model)\n",
    "    1. [Create input payload](#5.3.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#5.4.-Perform-real-time-inference)\n",
    "1. [Perform Batch inference](#6.-Perform-batch-inference)\n",
    "    1. [Batch transform](#6.1.-Batch-transform)\n",
    "    1. [Delete the model](#6.2.-Delete-the-model)\n",
    "1. [Model review by using Transformer (optional)](#7.-Model-review-by-using-Transformer-(optional))\n",
    "    1. [Available DFbVIF model output data items](#7.1.-Available-DFbVIF-model-output-data-items)\n",
    "    1. [Select DFbVIF model output data item for review](#7.2.-Select-DFbVIF-model-output-data-item-for-review)\n",
    "    1. [Model output review with Transformer](#7.3.-Model-output-review-with-Transformer)\n",
    "1. [Clean-up](#8.-Clean-up)\n",
    "    1. [Delete endpoint and model](#8.1.-Delete-endpoint-and-model)\n",
    "    1. [Unsubscribe to the listing (optional)](#8.2.-Unsubscribe-to-the-listing-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage instructions\n",
    "\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sagemaker Notebook\n",
    "\n",
    "For readers who like to review how to use Sagemaker Notebook in general, following Sagemaker documentation pages are best resources.  \n",
    "    [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)  \n",
    "    [Step 1: Create an Amazon SageMaker Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)  \n",
    "    [Step 2: Create a Jupyter Notebook](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-prepare.html)  \n",
    "    [Step 3: Download, Explore, and Transform a Dataset](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-preprocess-data.html)  \n",
    "    [Step 4: Train a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-train-model.html)  \n",
    "    [Step 5: Deploy the Model to Amazon EC2](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-model-deployment.html)  \n",
    "    [Step 6: Evaluate the Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-test-model.html)  \n",
    "    [Step 7: Clean Up](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "\n",
    "1. Open the algorithm listing page, [Dynamic factor based volatility index forecast (DFbVIF) mode](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?)\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your valid algorithm ARN\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{region}:123456789012:algorithm/{dfbvif_algorithm}'\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{}:{}:algorithm/{}'.format(\n",
    "#     'your_region', 'your_aws_account_number', 'your_dfbvif_algorithm_label')\n",
    "my_algorithm_arn = 'arn:aws:sagemaker:us-east-#:123456789012:algorithm/DFbVIF'\n",
    "my_prefix = 'dfbvif'\n",
    "\n",
    "# name of algorithm owned by my account\n",
    "my_own_algo_name = 'DFbVIF'\n",
    "\n",
    "# set type of volatility index forecast\n",
    "#     'uvf' for Volatility index forecasts with underlying volatility forecasts (UVF) as predictors\n",
    "#     'qar' for Volatility index forecasts by quadratic autoregressive (QAR) equation with QAR coefficients of underlying volatilities\n",
    "VIF_TYPE = 'qar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Prepare relevant environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "# remind\n",
    "print('Wait for Sagemaker values assigned to TWO important variables: my_bucket and my_role.\\n')\n",
    "\n",
    "# sagemaker session\n",
    "my_session = sagemaker.session.Session()\n",
    "\n",
    "# sagemaker attributes\n",
    "my_bucket = my_session.default_bucket()\n",
    "my_role = sagemaker.session.get_execution_role()\n",
    "\n",
    "# review\n",
    "print('my_session = {}'.format(my_session))\n",
    "print('my_bucket = {}'.format(my_bucket))\n",
    "print('my_role = {}'.format(my_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this Sagemaker machine learning ('ml') notebook example, following S3 folders are expected to be in place:\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. {my_bucket}/{my_prefix}/model/\n",
    "1. {my_bucket}/{my_prefix}/output/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 paths\n",
    "my_input_data_train_path = 's3://{}/{}/input/data/train'.format(my_bucket, my_prefix)\n",
    "my_input_data_infer_path = 's3://{}/{}/input/data/inference'.format(my_bucket, my_prefix)\n",
    "my_model_path = 's3://{}/{}/model'.format(my_bucket, my_prefix)\n",
    "my_output_data_infer_path = 's3://{}/{}/output/data/inference'.format(my_bucket, my_prefix)\n",
    "\n",
    "# dfbvif Docker container training channel\n",
    "training_input_channel = 'train'\n",
    "\n",
    "# aws computing instance type: 'ml.m5.xlarge'\n",
    "my_EC2 = 'ml.m5.xlarge'\n",
    "\n",
    "# input CSV data file name\n",
    "my_input_data_file = 'Weekly_MTS_6Yr.csv'\n",
    "\n",
    "# information available model and endpoint\n",
    "my_model_data = str()  # to be assigned / defined\n",
    "my_model_name = str()  # to be assigned / defined \n",
    "my_endpoint_name = 'my-endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are revisiting this demo notebook, and your model training job and/or your hyperparameter tuning job (to be defined later) were already run at least once, you can copy the resulted Sagemaker string values of your trained model data path and/or your tuned model data path to the variables, my_trained_model_data and/or my_tuned_model_data, in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model placeholder\n",
    "# my_trained_model_data = str()\n",
    "my_trained_model_data = str()\n",
    "my_trained_model_name = 'my-trained-model'\n",
    "\n",
    "# AVAILABLE trained model\n",
    "# IF model is trained and not to be trained again, copy-paste or type the full model data path for my_trained_model_data\n",
    "# my_trained_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "my_trained_model_data = (\n",
    "    's3://sagemaker-us-east-#-123456789012/dfbvif/model/my-training-job-.../output/model.tar.gz')\n",
    "\n",
    "# review\n",
    "print('Model data of trained model:')\n",
    "print(my_trained_model_data)\n",
    "print('Name of trained model:')\n",
    "print(my_trained_model_name)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# tuned model placeholder\n",
    "# my_tuned_model_data = str()\n",
    "my_tuned_model_data = str()\n",
    "my_tuned_model_name = 'my-tuned-model'\n",
    "\n",
    "# AVAILABLE tuned model\n",
    "# IF model is tuned and not to be tuned again, copy-paste or type the full model data path for my_tuned_model_data\n",
    "# my_tuned_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "#\n",
    "my_tuned_model_data = (\n",
    "    's3://sagemaker-us-east-#-123456789012/dfbvif/model/my-tuning-job-.../output/model.tar.gz')\n",
    "\n",
    "# review\n",
    "print('\\nModel data of tuned model:')\n",
    "print(my_tuned_model_data)\n",
    "print('Name of tuned model:')\n",
    "print(my_tuned_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [DFbVIF (Dynamic Factor based Volatility Index Forecast) algorithm](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?) needs THREE sets of input data: (1) multiple volatility index time-series, (2) multiple price/index/value time-series underlying the volatility indexes, and (3) multiple information-enhancing time-series dynamically correlated with the underlying time-series. The Sets 2 and 3 together is referred as DFM-input time-series.  \n",
    "  \n",
    "DFbVIF algorithm takes, as input data, all above three sets of multiple time-series together, contained in a CSV (comma separated value) data table, in the format of a CSV text-strings or a CSV text-file.  \n",
    "  \n",
    "Each row of the data table is an individual time-series. Row header is the label or symbol of the time-series. Each column is a sample at a specific moment in time. Column header is the time-index or time-stamp of the moment. The first data column is for the earliest time and the last column for the most recent time. The input data is essentially in the form of \"Row Time-Series of Column Vector\". The current version of DFbVIF requires equally spaced time-index.  \n",
    "  \n",
    "One of the simplest methods to generate a CSV text-file is to save a Microsoft Excel spreadsheet into a CSV file.  \n",
    "  \n",
    "You can also find more information about dataset format in **Usage Information** section of \n",
    "[Dynamic Factor Based Volatility Index Forecast (DFbVIF) Model](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Configure and visualize training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [sample data](https://github.com/i4cast/aws/blob/main/long_memory_vector_autoregressive_model/input/Weekly_VTS_6Yr.csv) provided with this product/example is six-year weekly (logarithmic) performances of mutual funds traded in the U.S. invested in equities, fixed income, and commodities. Each row is of an individual mutual fund. Each column is of a specific calendar week in history. The last week (the last column) was the week with a time-stamp as \"2024-12-27\". Following simple steps you can upload this sample data to your S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download sample dataset, https://github.com/i4cast/aws/blob/main/dfm-based_volatility_index_forecast_model/input/Weekly_MTS_6Yr.csv, and then upload the dataset to\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/ for training\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/ for inference\n",
    "\n",
    "following simple steps can be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open webpage: https://github.com/i4cast/aws/blob/main/dfm-based_volatility_index_forecast_model/input/Weekly_MTS_6Yr.csv\n",
    "1. Click [Raw] option located at top right of the data table\n",
    "1. In the Raw data window, right click [Save as]\n",
    "1. Set local file folder and file name in the \"Save As\" window, then click [Save]\n",
    "\n",
    "1. Open AWS S3 Console\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. Upload the saved local data file to your AWS S3 folder\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. Upload the saved local data file to your AWS S3 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about dataset format in **Hyperparameters** section of [Dynamic Factor Based Volatility Index Forecast Model (DFbVIF)](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "#     (all individual elements must be individual strings)\n",
    "my_hyperparam = {\n",
    "    'vol_index_dict': \"dict: {}\".format({\n",
    "        'VIXCLS': 'SPY',\n",
    "        'VXVCLS': None,\n",
    "        'VXDCLS': 'DIA',\n",
    "        'VXNCLS': 'QQQM',\n",
    "        'RVXCLS': 'VTWO',\n",
    "        'VXEEMCLS': 'EEM',\n",
    "        'VXEWZCLS': 'EWZ',\n",
    "        'GVZCLS': 'GLD',\n",
    "        'OVXCLS': 'USO',\n",
    "        'EVZCLS': 'FXE',\n",
    "        'VXAZNCLS': 'AMZN',\n",
    "        'VXAPLCLS': 'AAPL',\n",
    "        'VXGSCLS': 'GS',\n",
    "        'VXGOGCLS': 'GOOGL',\n",
    "        'VXIBMCLS': 'IBM'}),\n",
    "    'len_learn_window': '52',\n",
    "    'var_order': '13',\n",
    "    'num_factors': '10',\n",
    "    'ar_order_idio': '13',\n",
    "    'num_pcs': '2',\n",
    "    'alt_ar_order': \"dict: {}\".format({}),\n",
    "    'alt_num_pcs': \"dict: {}\".format({}),\n",
    "    'vif_type': \"{}\".format(VIF_TYPE),\n",
    "    'max_forecast_step': '13',\n",
    "    'num_forecasts': '13',\n",
    "    'eval_metric_list': \"list: {}\".format([\n",
    "        'r2_score',\n",
    "        'mean_squared_error',\n",
    "        'mean_absolute_error'\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Later in this example notebook\n",
    "#\n",
    "# Tuned hyperparameters:\n",
    "# {\n",
    "#     ...,\n",
    "#     'len_learn_window': 52,\n",
    "#     'var_order': 26,\n",
    "#     'num_factors': 5,\n",
    "#     'ar_order_idio': 13,\n",
    "#     'num_pcs': 4,\n",
    "#     'vif_type': 'qar',\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# list of available evaluation metrics\n",
    "#     'd2_absolute_error_score': not available with ubuntu 22.04\n",
    "#     'mean_absolute_percentage_error': not available with ubuntu 22.04\n",
    "metric_list = [\n",
    "    'r2_score', 'mean_squared_error', 'mean_absolute_error'\n",
    "]\n",
    "\n",
    "# list of available metric definitions\n",
    "#     'MetricDefinitions': metric_definition_list\n",
    "metric_definition_list = [\n",
    "    { 'Name': metric_list[0], 'Regex': '{}=(.*?);'.format(metric_list[0]) },\n",
    "    { 'Name': metric_list[1], 'Regex': '{}=(.*?);'.format(metric_list[1]) },\n",
    "    { 'Name': metric_list[2], 'Regex': '{}=(.*?);'.format(metric_list[2]) }\n",
    "]\n",
    "\n",
    "# list of available tuning objective metrics\n",
    "#     'SupportedTuningJobObjectiveMetrics': objective_metric_list\n",
    "objective_metric_list = [\n",
    "    { 'Type': 'Maximize', 'MetricName': metric_list[0] },\n",
    "    { 'Type': 'Minimize', 'MetricName': metric_list[1] },\n",
    "    { 'Type': 'Minimize', 'MetricName': metric_list[2] }\n",
    "]\n",
    "\n",
    "# review hyperparameters\n",
    "print('\\nHyperparameters:')\n",
    "print('my_hyperparam =')\n",
    "print(my_hyperparam)\n",
    "\n",
    "# review metric list\n",
    "print('\\nList of available evaluation metrics')\n",
    "print('metric_list =')\n",
    "print(metric_list)\n",
    "\n",
    "# review metric definitions\n",
    "print('\\nList of available metric definitions')\n",
    "print('metric_definition_list =')\n",
    "print(metric_definition_list)\n",
    "\n",
    "# reivew tuning objective metrics\n",
    "print('\\nList of available tuning objective metrics:')\n",
    "print('objective_metric_list =')\n",
    "print(objective_metric_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an estimator object for running a training job\n",
    "# Information on sagemaker.algorithm.AlgorithmEstimator():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "#\n",
    "my_estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=my_algorithm_arn,\n",
    "    role=my_role,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # volume_size=30,\n",
    "    # volume_kms_key=None,\n",
    "    # max_run=86400,\n",
    "    input_mode='File',\n",
    "    output_path=my_model_path,\n",
    "    # output_kms_key=None,\n",
    "    base_job_name='my-training-job',\n",
    "    sagemaker_session=my_session,\n",
    "    hyperparameters=my_hyperparam,\n",
    "    # tags=None,\n",
    "    # subnets=None,\n",
    "    # security_group_ids=None,\n",
    "    # model_uri=None,\n",
    "    model_channel_name='model',\n",
    "    metric_definitions=metric_definition_list # ,\n",
    "    # encrypt_inter_container_traffic=False,\n",
    "    # use_spot_instances=False,\n",
    "    # max_wait=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# Information on sagemaker.inputs.TrainingInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "#\n",
    "my_training_input = dict({\n",
    "    training_input_channel:\n",
    "        sagemaker.inputs.TrainingInput(\n",
    "            s3_data=my_input_data_train_path,\n",
    "            # distribution=None,\n",
    "            compression=None,\n",
    "            content_type='text/csv',\n",
    "            # record_wrapping=None,\n",
    "            s3_data_type='S3Prefix',\n",
    "            # instance_groups=None,\n",
    "            input_mode='File' # ,\n",
    "            # attribute_names=None,\n",
    "            # target_attribute_name=None,\n",
    "            # shuffle_config=None\n",
    ")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_training_job, to TRUE, in order to\n",
    "1. run [DFbVIF model](https://aws.amazon.com/marketplace/pp/prodview-p6f77e3yfnxbu?) training job\n",
    "1. save model artifacts of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training_job = True | False\n",
    "run_training_job = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_training_job above to TRUE and running model training job in the cell below, you can re-set run_training_job indicator back to FALSE in order to avoid accidentally running model training job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then train the model and save the result\n",
    "if run_training_job and (len(my_trained_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Train the model. Wait for training job completes with information:')\n",
    "    print('Model data of trained model\\n')\n",
    "    \n",
    "    # Information on sagemaker.algorithm.AlgorithmEstimator().fit()\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "    my_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All' # ,\n",
    "        # job_name=None\n",
    "    )\n",
    "    \n",
    "    # model data information\n",
    "    my_trained_model_data = my_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of trained model:')\n",
    "    print(my_trained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information how to visualize metrics during the process, see [Easily monitor and visualize metrics while training models on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/).\n",
    "\n",
    "You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune your model (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Tuning guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and/or forecasting different sets of multiple time-series require different values of hyperparameters: len_learn_window, var_order, num_factors, ar_order_idio, and num_pcs.\n",
    "\n",
    "Therefore, decisions on specific (integer) values of these hyperparameters need to be made before making meaningful training and inference. There are a variety of commonly practiced methods to estimate the appropriate hyperparameter values. When using AWS Sagemaker, it is natural to use Sagemaker's HyperparameterTuner class to search for appropriate hyperparameter values which result in better forecasts.\n",
    "\n",
    "For information about Automatic model tuning, also see [Perform Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Define tuning configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible ranges of appropriate hyperparameter values depend on specific dataset at hand. For the sample dataset used in this example, a set of reasonable ranges of hyperparameter values are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.IntegerParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "int_hyperpar_range_example = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=52, max_value=157, scaling_type='Auto'),\n",
    "    'var_order':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=52, scaling_type='Auto'),\n",
    "    'num_factors':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=30, scaling_type='Auto'),\n",
    "    'ar_order_idio':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=52, scaling_type='Auto'),\n",
    "    'num_pcs':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=20, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural seasonality of time-series and some \"rule of thumb for choices\" may be utilized to focus on a few reasonable values within reasonable ranges. Following example can be used for a simpler model tuning.\n",
    "\n",
    "For general information about AWS SageMaker Hyperparameter Tuning, referred to [How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) and [Define Hyperparameter Ranges](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.CategoricalParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "my_hyperparam_range = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.CategoricalParameter(['52', '105']),\n",
    "    'var_order':\n",
    "        sagemaker.parameter.CategoricalParameter(['13', '26']),\n",
    "    'num_factors':\n",
    "        sagemaker.parameter.CategoricalParameter(['5', '10', '15', '20']),\n",
    "    'ar_order_idio':\n",
    "        sagemaker.parameter.CategoricalParameter(['4', '13']),\n",
    "    'num_pcs':\n",
    "        sagemaker.parameter.CategoricalParameter(['2', '4', '6']),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different inference applications need to use different metrics to measure relevant goodness of fit. In this example, we try to forecast future performances of U.S. mutual funds. Proportionalities (a quantifiable version of similarity) between forecasted and realized absolute performances can serve as a useful measure of goodness of fit.\n",
    "\n",
    "If we regard a set of forecasted or realized absolute performances as a multi-dimensional vector, projection of one vector (e.g. forecasted) onto the other (e.g. realized) is a measure of \"proportionality (or similarity) between the two sets of absolute performances\".\n",
    "\n",
    "Therefore, we use the \"projection coefficient\" as the objective metric for tuning the hyperparameters.\n",
    "\n",
    "For general information about AWS SageMaker Metrics, referred to [Define Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of available evaluation metrics\n",
    "# metric_list = [\n",
    "#     'r2_score', 'mean_squared_error', 'mean_absolute_error']\n",
    "#\n",
    "# list of available metric definitions\n",
    "# metric_definition_list = [\n",
    "#     { 'Name': metric_list[0], 'Regex': '{}=(.*?);'.format(metric_list[0]) },\n",
    "#     { 'Name': metric_list[1], 'Regex': '{}=(.*?);'.format(metric_list[1]) },\n",
    "#     { 'Name': metric_list[2], 'Regex': '{}=(.*?);'.format(metric_list[2]) }]\n",
    "#\n",
    "# list of available tuning objective metrics\n",
    "# objective_metric_list = [\n",
    "#     { 'Type': 'Maximize', 'MetricName': metric_list[0] },\n",
    "#     { 'Type': 'Minimize', 'MetricName': metric_list[1] },\n",
    "#     { 'Type': 'Minimize', 'MetricName': metric_list[2] }]\n",
    "\n",
    "# review metric list\n",
    "print('\\nList of available evaluation metrics')\n",
    "print('metric_list =')\n",
    "print(metric_list)\n",
    "\n",
    "# review metric definitions\n",
    "print('\\nList of available metric definitions')\n",
    "print('metric_definition_list =')\n",
    "print(metric_definition_list)\n",
    "\n",
    "# reivew tuning objective metrics\n",
    "print('\\nList of available tuning objective metrics:')\n",
    "print('objective_metric_list =')\n",
    "print(objective_metric_list)\n",
    "\n",
    "# choice of evaluation metric for hyperparameter tuning\n",
    "#     metric_id = 0 or 1 or 2\n",
    "metric_id = 2\n",
    "\n",
    "# my_objective_metric\n",
    "my_objective_metric = metric_definition_list[metric_id]['Name']\n",
    "\n",
    "# my_objective_type\n",
    "my_objective_type = objective_metric_list[metric_id]['Type']\n",
    "\n",
    "# review metric for hyperparameter tuning\n",
    "print('\\nTuning metric')\n",
    "print(my_objective_metric)\n",
    "\n",
    "# review objective of turing metric\n",
    "print('\\nTuning objective\\n')\n",
    "print(my_objective_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Run a model tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up hyperparameter tuning job\n",
    "# Information on sagemaker.tuner.HyperparameterTuner():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "#\n",
    "# Notes on an AWS Sagemaker requirement:\n",
    "# when calling the CreateHyperParameterTuningJob operation,\n",
    "# you can’t override the metric definitions for AWS Marketplace algorithms.\n",
    "# try the request without specifying metric definitions.\n",
    "#\n",
    "my_tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=my_estimator,\n",
    "    objective_metric_name=my_objective_metric,\n",
    "    hyperparameter_ranges=my_hyperparam_range,\n",
    "    # metric_definitions=None,\n",
    "    # strategy='Bayesian',\n",
    "    objective_type=my_objective_type,\n",
    "    max_jobs=1,\n",
    "    max_parallel_jobs=1,\n",
    "    # max_runtime_in_seconds=None,\n",
    "    # tags=None,\n",
    "    base_tuning_job_name='my-tuning-job',\n",
    "    # warm_start_config=None,\n",
    "    # strategy_config=None,\n",
    "    # completion_criteria_config=None,\n",
    "    early_stopping_type='Auto' # ,\n",
    "    # estimator_name=None,\n",
    "    # random_seed=None,\n",
    "    # autotune=False,\n",
    "    # hyperparameters_to_keep_static=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_tuning_job, to TRUE, in order to\n",
    "1. run hyperparameter optimization job\n",
    "1. save optimal model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tuning_job = True | False\n",
    "run_tuning_job = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_tuning_job above to TRUE and running hyperparameter tuning job in the cell below, you can re-set run_tuning_job indicator back to FALSE in order to avoid accidentally running hyperparameter tuning job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then optimize model and save the result\n",
    "if run_tuning_job and (len(my_tuned_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Tune the model. Wait for tuning job completes with information:')\n",
    "    print('Model data of tuned model\\n')\n",
    "    \n",
    "    # tuning and waiting\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().fit():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuner.fit(\n",
    "        inputs=my_training_input)\n",
    "    my_tuner.wait()\n",
    "    \n",
    "    # get tuned model and artfacts of the tuned model\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().best_estimator():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuned_estimator = my_tuner.best_estimator()\n",
    "    my_tuned_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All')\n",
    "    \n",
    "    # optimized hyperparameters\n",
    "    my_tuned_hyperparam = my_tuned_estimator.hyperparameters()\n",
    "    \n",
    "    # optimal model artfacts\n",
    "    my_tuned_model_data = my_tuned_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nTuned hyperparameters:')\n",
    "    print(my_tuned_hyperparam)\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of tuned model:')\n",
    "    print(my_tuned_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recommended by AWS Sagemaker Team, once you have completed a tuning job, (or even while the job is still running) you can [clone and use this notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to analyze the results to understand how each hyperparameter effects the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available trained model\n",
    "if len(my_trained_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_trained_model_data\n",
    "    my_model_name = my_trained_model_name\n",
    "\n",
    "# available tuned model\n",
    "if len(my_tuned_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_tuned_model_data\n",
    "    my_model_name = my_tuned_model_name\n",
    "\n",
    "# Information on sagemaker.model.ModelPackage():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_model = sagemaker.model.ModelPackage(\n",
    "    role=my_role,\n",
    "    model_data=my_model_data,\n",
    "    # algorithm_arn=my_algorithm_arn, # algorithm arn used to train the model\n",
    "    algorithm_arn=my_own_algo_name, # OR just the name if your account owns the algorithm\n",
    "    # model_package_arn=None,\n",
    "    # -----------------------\n",
    "    # other **kwargs include:\n",
    "    # image_uri,\n",
    "    # predictor_cls=None,\n",
    "    # env=None,\n",
    "    name=my_model_name,\n",
    "    # vpc_config=None,\n",
    "    sagemaker_session=my_session # ,\n",
    "    # enable_network_isolation=None,\n",
    "    # model_kms_key=None,\n",
    "    # image_config=None,\n",
    "    # source_dir=None,\n",
    "    # code_location=None,\n",
    "    # entry_point=None,\n",
    "    # container_log_level=20,\n",
    "    # dependencies=None,\n",
    "    # git_config=None,\n",
    "    # resources=None\n",
    ")\n",
    "\n",
    "# review\n",
    "print('Name of model:')\n",
    "print(my_model_name)\n",
    "\n",
    "# review\n",
    "print('\\nArtifacts of model:')\n",
    "print(my_model_data)\n",
    "\n",
    "# review\n",
    "print('\\nModel pacakge')\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Deploy trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Start endpoint for inference. Wait for endpoint becomes ready')\n",
    "\n",
    "# Information on sagemaker.serializers.IdentitySerializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html\n",
    "my_serializer = sagemaker.serializers.IdentitySerializer()\n",
    "\n",
    "# Information on sagemaker.deserializers.StreamDeserializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html\n",
    "my_deserializer = sagemaker.deserializers.StreamDeserializer()\n",
    "\n",
    "# Information on sagemaker.model.Model().deploy():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_endpoint = my_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer,\n",
    "    # accelerator_type=None,\n",
    "    endpoint_name=my_endpoint_name # ,\n",
    "    # tags=None,\n",
    "    # kms_key=None,\n",
    "    # wait=True,\n",
    "    # data_capture_config=None,\n",
    "    # async_inference_config=None,\n",
    "    # serverless_inference_config=None,\n",
    "    # volume_size=None,\n",
    "    # model_data_download_timeout=None,\n",
    "    # container_startup_health_check_timeout=None,\n",
    "    # inference_recommendation_id=None,\n",
    "    # explainer_config=None,\n",
    "    # accept_eula=None,\n",
    "    # endpoint_logging=False\n",
    "    # resources=None,\n",
    "    # endpoint_type=<EndpointType.MODEL_BASED: 'ModelBased'>,\n",
    "    # managed_instance_scaling=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# review\n",
    "print('\\nSagemaker endpoint, ' + my_endpoint_name + ', is now ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "# Information on sagemaker.predictor.Predictor():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=my_endpoint_name,\n",
    "    sagemaker_session=my_session,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer # ,\n",
    "    # component_name=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# review\n",
    "print(my_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input payload can be created by following functions of the class [S3 Utilities](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html)\n",
    "\n",
    "1. **sagemaker.s3.s3_path_join(\\*args)**: similarly to os.path.join()\n",
    "1. **sagemaker.s3.S3Downloader.read_file(s3_uri, sagemaker_session=None)**: returns the contents of an s3 uri file body as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file for inference\n",
    "my_infer_input_file = sagemaker.s3.s3_path_join(\n",
    "    my_input_data_infer_path,\n",
    "    my_input_data_file)\n",
    "\n",
    "# CSV data: string\n",
    "my_infer_input_str = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_infer_input_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# CSV data: byte stream object\n",
    "my_inference_input_obj = my_infer_input_str.encode()\n",
    "\n",
    "# review\n",
    "print('my_infer_input_file:')\n",
    "print(my_infer_input_file + '\\n')\n",
    "\n",
    "# review\n",
    "print('my_infer_input_str: ' + str(type(my_infer_input_str)))\n",
    "print('my_inference_input_obj: ' + str(type(my_inference_input_obj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().predict():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_forecast = my_predictor.predict(\n",
    "    data=my_inference_input_obj # ,\n",
    "    # initial_args=None,\n",
    "    # target_model=None,\n",
    "    # target_variant=None,\n",
    "    # inference_id=None,\n",
    "    # custom_attributes=None,\n",
    "    # component_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review\n",
    "print('Output of real-time inference:')\n",
    "print(my_forecast)\n",
    "\n",
    "# review\n",
    "# Information on botocore.response.StreamingBody()\n",
    "# https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html\n",
    "print('\\nReal-time forecasts of time-series')\n",
    "print(my_forecast[0].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate it to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default inference ENV variables\n",
    "my_ENV = dict({\n",
    "    'MODELOUTPUT': 'vil_forecast'\n",
    "})\n",
    "\n",
    "# available output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    1\n",
    "]\n",
    "# Notes: output data file of type 'text/csv'\n",
    "# can be reviewed simply by a simple text edidtor\n",
    "\n",
    "# Information sagemaker.transformer.Transformer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # strategy=None,\n",
    "    # assemble_with=None,\n",
    "    output_path=my_output_data_infer_path,\n",
    "    # output_kms_key=None,\n",
    "    accept=output_type,\n",
    "    # max_concurrent_transforms=None,\n",
    "    # max_payload=None,\n",
    "    # tags=None,\n",
    "    env=my_ENV,\n",
    "    # base_transform_job_name=None,\n",
    "    sagemaker_session=my_session # ,\n",
    "    # volume_kms_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Batch-transform job input file is located in the S3 folder: {my_bucket}/{my_prefix}/input/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.inputs.TransformInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "my_transform_data_path = my_input_data_infer_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    compression_type=None,\n",
    "    # split_type=None,\n",
    "    # job_name=None,\n",
    "    # input_filter=None,\n",
    "    # output_filter=None, \n",
    "    # join_source=None,\n",
    "    # experiment_config=None,\n",
    "    # model_client_config=None,\n",
    "    # batch_data_capture_config=None,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# review\n",
    "print('Output of batch transform job:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the transform output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"vil_forecast.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"vil_forecast.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Delete the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a batch inference. IF you plan to review the trained or tuned model structure by using Transformer as demonstrated later, do NOT run the cell below. Otherwise, you can delete the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need more batch transform?\n",
    "more_batch_transform = True\n",
    "\n",
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "if not more_batch_transform:\n",
    "    my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model review by using Transformer (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Available DFbVIF model output data items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"stdev\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    stdev_vec = DFbVIF_obj.get_stdev()  \n",
    "    \n",
    "    stdev_vec : pd.Series, index (ts_list)  \n",
    "        Sample standard deviation vector of DFM-input  \n",
    "            vector time-series on data points in last  \n",
    "            learning window  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"all_var_base\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "  \n",
    "    all_var_base = DFbVIF_obj.get_all_var_base()  \n",
    "    \n",
    "    all_var_base : pd.DataFrame, index (ts_list),  \n",
    "            columns (all_step_list + ['asof'])  \n",
    "        All estimated and forecasted base-case variance  \n",
    "            of base-case time-series of DFM-input vector  \n",
    "            time-series, estimated and forecasted by  \n",
    "            DFM-based volatility forecast model DFVCM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"all_variance\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "  \n",
    "    all_variance = DFbVIF_obj.get_all_variance()  \n",
    "    \n",
    "    all_variance : pd.DataFrame, index (ts_list),  \n",
    "            columns (all_step_list + ['asof'])  \n",
    "        All estimated and forecasted variance of  \n",
    "            DFM-inputd vector time-series, estimated  \n",
    "            and forecasted by DFM-based volatility  \n",
    "            forecast model DFVCM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"indiv_var_parts\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    indiv_var_parts = DFbVIF_obj.get_indiv_var_parts()  \n",
    "    \n",
    "    indiv_var_parts : dict, keys ('comm', 'idio', 'asof')  \n",
    "            obj['comm'] : pd.DataFrame, index (ts_list),  \n",
    "                columns (comm_lagtub_list + ['pred_err'])  \n",
    "            obj['idio'] : pd.DataFrame, index (ts_list),  \n",
    "                columns (idio_lagtub_list + ['pred_err'])  \n",
    "        Parts of variance of individual time-series of  \n",
    "            DFM-input vector time-series, predicted by  \n",
    "            dynamic common factors for obj['comm'], and  \n",
    "            by idiosycratic UDC for obj['idio']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"und_variance\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    und_variance, mult_uvf = DFbVIF_obj.get_und_variance()  \n",
    "    \n",
    "    und_variance : pd.DataFrame, index (idx_list),  \n",
    "            columns (all_step_list + ['asof'])  \n",
    "        All estimated and forecasted variance of VI-  \n",
    "            adjusted underlying time-series (underlying  \n",
    "            volatility indexes)  \n",
    "    \n",
    "    mult_uvf : pd.Series, index (idx_list)  \n",
    "        Multiplier of value-adjustment of UVF  \n",
    "            (underlying volatility forecasts  \n",
    "            as predictors) method forecasting  \n",
    "            implied variance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"qar_coefs\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "  \n",
    "    (qar_coef_comm, qar_coef_idio,\n",
    "        const_qar, mult_qar, min_vi2f_ratio\n",
    "        ) = DFbVIF_obj.get_qar_coefs()\n",
    "    \n",
    "    qar_coef_comm : pd.DataFrame, index (idx_list),  \n",
    "            columns (comm_lagtup_list + ['asof'])  \n",
    "        Diagonal factor-based QAR coefficient  \n",
    "            matrixes in 1-step forecast of variance  \n",
    "            of underlying time-series  \n",
    "    \n",
    "    qar_coef_idio : pd.DataFrame, index (idx_list),  \n",
    "            columns (idio_lagtup_list + ['asof'])  \n",
    "        Diagonal UDC-based QAR coefficient  \n",
    "            matrixes in 1-step forecast of  \n",
    "            variance of underlying time-series  \n",
    "    \n",
    "    const_qar : pd.Series, index (idx_list)  \n",
    "        Additive constant of value-adjustment  \n",
    "            of QAR (quadratic autoregressive)  \n",
    "            method forecasting implied variance  \n",
    "    \n",
    "    mult_qar : pd.Series, index (idx_list),  \n",
    "        Multiplier of value-adjustment of QAR  \n",
    "            (quadratic autoregressive) method  \n",
    "            forecasting implied variance  \n",
    "    \n",
    "    min_vi2f_ratio : pd.DataFrame,  \n",
    "            index (idx_list),  \n",
    "            columns (vcf_step_list)  \n",
    "        Minimum realized s-step ratio of implied  \n",
    "            vairiance, VI2(t) Inv( VI2(t-s) ),  \n",
    "            serving as lower limit of forecasted  \n",
    "            implied variance over last observed  \n",
    "            value, VI2(t+s|t) Inv( VI2(t) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vi2_forec\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vi2_forec = DFbVIF_obj.get_vi2_forec()  \n",
    "    \n",
    "    vi2_forec : pd.DataFrame, index (idx_list),  \n",
    "            columns (vcf_step_list + ['asof'])  \n",
    "        Multi-step multivariate forecasts of\n",
    "            implied variances  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vi2_forec_ratio\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vi2_forec_ratio = DFbVIF_obj.get_vi2_forec_ratio()  \n",
    "    \n",
    "    vi2_forec_ratio : pd.DataFrame, index (idx_list),  \n",
    "            columns (vcf_step_list + ['asof'])  \n",
    "        Ratios of UVF and QAR forecasts of implied  \n",
    "            variances over realized values of implied  \n",
    "            variances  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vi2_attrib\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vi2_attrib = DFbVIF_obj.get_vi2_attrib()  \n",
    "    \n",
    "    vi2_attrib : pd.DataFrame, index (idx_list),  \n",
    "            columns (vi2_source_list + ['asof'])  \n",
    "        Weights of attribution of forecast (of  \n",
    "            implied variance) to dynamic sources  \n",
    "            of volatility of volatility indexes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vil_forecast\"**  \n",
    "    \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vil_forecast = DFbVIF_obj.get_vil_forecast()  \n",
    "    \n",
    "    vil_forecast : pd.DataFrame, index (idx_list),  \n",
    "            columns (vcf_step_list + ['asof'])  \n",
    "        Multi-step multivariate forecasts of  \n",
    "            volatility indexes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Select DFbVIF model output data item for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained or tuned DFbVIF model output can be reviewed item by item using Transformer  \n",
    "with an environment variable, MODELOUTPUT  \n",
    "  \n",
    "Choices of values of MODELOUTPUT are:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available choices for MODELOUTPUT\n",
    "model_output_choice = dict({\n",
    "     1: 'stdev',\n",
    "     2: 'all_var_base',\n",
    "     3: 'all_variance',\n",
    "     4: 'indiv_var_parts',\n",
    "     5: 'und_variance',\n",
    "     6: 'qar_coefs',\n",
    "     7: 'vi2_forec',\n",
    "     8: 'vi2_forec_ratio',\n",
    "     9: 'vi2_attrib',\n",
    "    10: 'vil_forecast'\n",
    "})\n",
    "\n",
    "# available choices for output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make any valid pair of choices as exemplified as in following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice for MODELOUTPUT (an integer between 1 and 6)\n",
    "model_output = model_output_choice[\n",
    "    9\n",
    "]\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    1\n",
    "]\n",
    "# Notes: output data file of type 'text/csv'\n",
    "# can be reviewed simply by a simple text edidtor\n",
    "\n",
    "# review\n",
    "print('model_output = ' + model_output)\n",
    "print('output_type = ' + output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Model output review with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV variables\n",
    "my_ENV = dict({\n",
    "    'MODELOUTPUT': model_output})\n",
    "\n",
    "# sagemaker.transformer.Transformer()\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # strategy=None,\n",
    "    # assemble_with=None,\n",
    "    output_path=my_output_data_infer_path,\n",
    "    # output_kms_key=None,\n",
    "    accept=output_type,\n",
    "    # max_concurrent_transforms=None,\n",
    "    # max_payload=None,\n",
    "    # tags=None,\n",
    "    env=my_ENV,\n",
    "    # base_transform_job_name=None,\n",
    "    sagemaker_session=my_session # ,\n",
    "    # volume_kms_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.inputs.TransformInput()\n",
    "my_transform_data_path = my_input_data_infer_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'\n",
    "\n",
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    compression_type=None,\n",
    "    # split_type=None,\n",
    "    # job_name=None,\n",
    "    # input_filter=None,\n",
    "    # output_filter=None, \n",
    "    # join_source=None,\n",
    "    # experiment_config=None,\n",
    "    # model_client_config=None,\n",
    "    # batch_data_capture_config=None,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# display\n",
    "print('Selected output:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the selected output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"{model_output}.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"{model_output}.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Delete endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:  \n",
    "\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
