{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, deploy and review ML algorithm/model LMDFM (long-memory dynamic factor model) from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of the algorithm  \n",
    "  \n",
    "The long-memory dynamic factor model (LMDFM) algorithm is developed to make  \n",
    "1. analysis of observed multiple (vector) time-series,  \n",
    "1. multi-step forecasts of multivariate (vector) time-series, and  \n",
    "1. multi-step forecasts of multivariate volatility (variance-covariance matrix) of vector time-series.  \n",
    "  \n",
    "The LMDFM model assumes that the large set of time-series are influenced by evolution histories of a number of unobserved factors commonly affecting all or many of the time-series. LMDFM is estimated by an implementation of dynamic principal components analysis (DPCA), reviewed by Doz and Fuleky (2020), with 2-dimensional discrete Fourier transform (2D-DFT). LMDFM algorithm can estimate the influences of longer histories of common factors and avoid over-fitting. The algorithm accommodates wider ranges of values of model learning parameters. The wider ranges can further enhance the power of machine learning.  \n",
    "  \n",
    "Current version of the LMDFM algorithm estimates: (a) dynamic factor loadings matrixes, (b) vector autoregressive (VAR) coefficients of dynamic factor scores, (c) multi-step forecasts of the factor scores and of the observed time-series, (d) impulse response of the time-series to several simultaneous shocks, and (e) multi-step forecasts of variance-covariance matrix of the factor scores and of the observed time-series; etc. Other estimates will be added in the future releases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Academic publications on dynamic factor models (DFMs)\n",
    "  \n",
    "L. Alessi, M. Barigozzi and M. Capasso  (2007).  \"Dynamic factor GARCH: Multivariate volatility forecast for a large number of series\".  LEM Working Paper Series, No. 2006/25, Laboratory of Economics and Management (LEM), Pisa.  \n",
    "   \n",
    "C. Doz  and  P. Fuleky  (2020).  \"Chapter 2,  Dynamic Factor Models\" in Macroeconomic Forecasting in the Era of Big Data: Theory and Practice, Ed. P. Fuleky,  Advanced Studies in Theoretical and Applied Econometrics, Volume 52.  Springer.  https://www.springer.com/gp/book/9783030311490 or manuscript https://halshs.archives-ouvertes.fr/halshs-02262202/document.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook\n",
    "\n",
    "This sample notebook shows you how to train, tune, deploy and understand a custom ML algorithm/model: [Long-Memory Dynamic Factor Model (LMDFM)](https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa), guided by common practices to [Use Algorithm and Model Package Resources](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-buy.html).\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    1. or your AWS account has a subscription to [Long-Memory Dynamic Factor Model (LMDFM)](https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "    1. [Subscription](#1.1.-Subscription)\n",
    "    1. [Prepare relevant environment](#1.2.-Prepare-relevant-environment)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "    1. [Dataset format expected by the algorithm](#2.1.-Dataset-format-expected-by-the-algorithm)\n",
    "    1. [Configure and visualize training dataset](#2.2.-Configure-and-visualize-training-dataset)\n",
    "    1. [Upload datasets to Amazon S3](#2.3.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3.-Train-a-machine-learning-model)\n",
    "    1. [Set hyperparameters](#3.1.-Set-hyperparameters)\n",
    "    1. [Train a model](#3.2.-Train-a-model)\n",
    "1. [Tune your model (optional)](#4.-Tune-your-model-(optional))\n",
    "    1. [Tuning Guidelines](#4.1.-Tuning-guidelines)\n",
    "    1. [Define Tuning configuration](#4.2.-Define-tuning-configuration)\n",
    "    1. [Run a model tuning job](#4.3.-Run-a-model-tuning-job)\n",
    "1. [Deploy model and verify results](#5.-Deploy-model-and-verify-results)\n",
    "    1. [Trained or tuned model](#5.1.-Trained-or-tuned-model)\n",
    "    1. [Deploy trained or tuned model](#5.2.-Deploy-trained-or-tuned-model)\n",
    "    1. [Create input payload](#5.3.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#5.4.-Perform-real-time-inference)\n",
    "1. [Perform Batch inference](#6.-Perform-batch-inference)\n",
    "    1. [Batch transform](#6.1.-Batch-transform)\n",
    "    1. [Delete the model](#6.2.-Delete-the-model)\n",
    "1. [Model review by using Transformer (optional)](#7.-Model-review-by-using-Transformer-(optional))\n",
    "    1. [Available LMDFM model output data items](#7.1.-Available-LMDFM-model-output-data-items)\n",
    "    1. [Select LMDFM model output data item for review](#7.2.-Select-LMDFM-model-output-data-item-for-review)\n",
    "    1. [Model structure review with Transformer](#7.3.-Model-structure-review-with-Transformer)\n",
    "1. [Clean-up](#8.-Clean-up)\n",
    "    1. [Delete endpoint and model](#8.1.-Delete-endpoint-and-model)\n",
    "    1. [Unsubscribe to the listing (optional)](#8.2.-Unsubscribe-to-the-listing-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage instructions\n",
    "\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sagemaker Notebook\n",
    "\n",
    "For readers who like to review how to use Sagemaker Notebook in general, following Sagemaker documentation pages are best resources.  \n",
    "    [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)  \n",
    "    [Step 1: Create an Amazon SageMaker Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)  \n",
    "    [Step 2: Create a Jupyter Notebook](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-prepare.html)  \n",
    "    [Step 3: Download, Explore, and Transform a Dataset](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-preprocess-data.html)  \n",
    "    [Step 4: Train a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-train-model.html)  \n",
    "    [Step 5: Deploy the Model to Amazon EC2](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-model-deployment.html)  \n",
    "    [Step 6: Evaluate the Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-test-model.html)  \n",
    "    [Step 7: Clean Up](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "\n",
    "1. Open the algorithm listing page, [Long-Memory Dynamic Factor Model (LMDFM)](\n",
    "https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your valid algorithm ARN\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{region}:123456789012:algorithm/{lmdfm_algorithm}'\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{}:{}:algorithm/{}'.format(\n",
    "#     'your_region', 'your_aws_account_number', 'your_lmdfm_algorithm_label')\n",
    "my_algorithm_arn = 'arn:aws:sagemaker:us-east-1:123456789012:algorithm/lmdfm-v'\n",
    "my_prefix = 'lmdfm'\n",
    "\n",
    "# LMDFM algorithm/model training/inference utility\n",
    "# DFM_UTILITY = 'timeseries':\n",
    "#     for utilizing LMDFM to make multi-step multivariate time-series forecasts\n",
    "# DFM_UTILITY = 'volatility':\n",
    "#     for uitlizing LMDFM to make multi-step multivariate volatility forecasts\n",
    "DFM_UTILITY = 'volatility'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Prepare relevant environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "# remind\n",
    "print('Wait for Sagemaker values assigned to TWO important variables: my_bucket and my_role.\\n')\n",
    "\n",
    "# sagemaker session\n",
    "my_session = sagemaker.session.Session()\n",
    "\n",
    "# sagemaker attributes\n",
    "my_bucket = my_session.default_bucket()\n",
    "my_role = sagemaker.session.get_execution_role()\n",
    "\n",
    "# review\n",
    "print('my_bucket = {}'.format(my_bucket))\n",
    "print('my_role = {}'.format(my_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this Sagemaker machine learning ('ml') notebook example, following S3 folders are expected to be in place:\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. {my_bucket}/{my_prefix}/model/\n",
    "1. {my_bucket}/{my_prefix}/output/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 paths\n",
    "my_input_data_train_path = 's3://{}/{}/input/data/train'.format(my_bucket, my_prefix)\n",
    "my_input_data_infer_path = 's3://{}/{}/input/data/inference'.format(my_bucket, my_prefix)\n",
    "my_model_path = 's3://{}/{}/model'.format(my_bucket, my_prefix)\n",
    "my_output_data_infer_path = 's3://{}/{}/output/data/inference'.format(my_bucket, my_prefix)\n",
    "\n",
    "# lmdfm Docker container training channel\n",
    "training_input_channel = 'train'\n",
    "\n",
    "# aws computing instance type: 'ml.m5.xlarge'\n",
    "my_EC2 = 'ml.m5.xlarge'\n",
    "\n",
    "# input CSV data file name\n",
    "my_input_data_file = 'Weekly_VTS_6Yr.csv'\n",
    "\n",
    "# information available model and endpoint\n",
    "my_model_data = str()  # to be assigned / defined\n",
    "my_model_name = str()  # to be assigned / defined \n",
    "my_endpoint_name = 'my-endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are revisiting this demo notebook, and your model training job and/or your hyperparameter tuning job (to be defined later) were already run at least once, you can copy the resulted Sagemaker string values of your trained model data path and/or your tuned model data path to the variables, my_trained_model_data and/or my_tuned_model_data, in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model placeholder\n",
    "# my_trained_model_data = str()\n",
    "my_trained_model_data = str()\n",
    "my_trained_model_name = 'my-trained-model'\n",
    "\n",
    "# tuned model placeholder\n",
    "# my_tuned_model_data = str()\n",
    "my_tuned_model_data = str()\n",
    "my_tuned_model_name = 'my-tuned-model'\n",
    "\n",
    "# model_utility = 'timeseries'\n",
    "if DFM_UTILITY in ['timeseries']:\n",
    "    \n",
    "    # AVAILABLE trained model\n",
    "    # IF model is trained and not to be trained again, copy-paste or type the full model data path for my_trained_model_data\n",
    "    # my_trained_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_trained_model_data = (\n",
    "        's3://sagemaker-us-east-1-123456789012/lmdfm/model/my-training-job/output/model.tar.gz')\n",
    "    \n",
    "    # AVAILABLE tuned model\n",
    "    # IF model is tuned and not to be tuned again, copy-paste or type the full model data path for my_tuned_model_data\n",
    "    # my_tuned_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_tuned_model_data = (\n",
    "        's3://sagemaker-us-east-1-123456789012/lmdfm/model/my-tuning-job/output/model.tar.gz')\n",
    "    \n",
    "# model_utility = 'volatility'\n",
    "if DFM_UTILITY in ['volatility']:\n",
    "    \n",
    "    # AVAILABLE trained model\n",
    "    # IF model is trained and not to be trained again, copy-paste or type the full model data path for my_trained_model_data\n",
    "    # my_trained_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_trained_model_data = (\n",
    "        's3://sagemaker-us-east-1-123456789012/lmdfm/model/my-training-job/output/model.tar.gz')\n",
    "    \n",
    "    # AVAILABLE tuned model\n",
    "    # IF model is tuned and not to be tuned again, copy-paste or type the full model data path for my_tuned_model_data\n",
    "    # my_tuned_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_tuned_model_data = (\n",
    "        's3://sagemaker-us-east-1-123456789012/lmdfm/model/my-tuning-job/output/model.tar.gz')\n",
    "\n",
    "# review\n",
    "print('Model data of trained model:')\n",
    "print(my_trained_model_data)\n",
    "print('Name of trained model:')\n",
    "print(my_trained_model_name)\n",
    "\n",
    "# review\n",
    "print('\\nModel data of tuned model:')\n",
    "print(my_tuned_model_data)\n",
    "print('Name of tuned model:')\n",
    "print(my_tuned_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LMDFM (long-memory dynamic factor model) algorithm takes, as input data,\n",
    "multiple time-series data contained in a CSV (comma separated value) data table, in a format of a CSV text-string or a CSV text-file.\n",
    "\n",
    "Each row of the data table is for values of an individual time-series (TS). Row header is the label or symbol of the time-series.\n",
    "Each column is for values of all time-series at a specific moment in time. Column header is the time-index or time-stamp of the moment.\n",
    "The first data column is for the earliest time and the last column for the most recent time.\n",
    "Therefore, the first row of the CSV data table is \"Label/Symbol/Description, earliest time-stamp, next time-stamp, ..., most recent time-stamp\".\n",
    "The first column of the CSV table is \"Label/Symbol/Description, label of 1st TS, label of 2nd TS, ..., label of last TS\".\n",
    "The current version of LMDFM requires equally spaced time-stamps.\n",
    "\n",
    "Since LMDFM forecasts future values of multiple time-series using \"Vector Autoregressive (VAR)\" model estimated by \"Dynamic Factor Model (DFM)\",\n",
    "the input data is essentially in the form of \"Row Time-Series of Column Vector\".\n",
    "\n",
    "One of the simplest methods to generate such a CSV text-file is to save a Microsoft Excel spreadsheet as (into) a CSV file.\n",
    "\n",
    "You can also find more information about dataset format in **Usage Information** section of \n",
    "[Long-Memory Dynamic Factor Model (LMDFM)](\n",
    "https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Configure and visualize training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [sample data](https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/input/Weekly_VTS_6Yr.csv) provided with this product/example is six-year weekly (logarithmic) performances of mutual funds traded in the U.S. invested in equities, fixed income, and commodities. Each row is of an individual mutual fund. Each column is of a specific calendar week in history. The last week (the last column) was the week with a time-stamp as \"2021-12-31\". Following simple steps you can upload this sample data to your S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the sample dataset from https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/input/Weekly_VTS_6Yr.csv, and then upload the dataset to\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/ for training\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/ for inference\n",
    "\n",
    "following simple steps can be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open webpage https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/input/Weekly_VTS_6Yr.csv\n",
    "1. Click [Raw] option located at top right of the data table\n",
    "1. In the Raw data window, right click [Save as]\n",
    "1. Set local file folder and file name in the \"Save As\" window, then click [Save]\n",
    "\n",
    "1. Open AWS S3 Console\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. Upload the saved local data file to your AWS S3 folder\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. Upload the saved local data file to your AWS S3 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about dataset format in **Hyperparameters** section of [Long-Memory Dynamic Factor Model (LMDFM)](https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half_life_list and eval_metric_list\n",
    "half_life_list = ['13', '26', '52']\n",
    "eval_metric_list = ['projection_coefficient']\n",
    "\n",
    "# variance_type_list and variance_score_list\n",
    "variance_type_list = list(['diff_FE', 'diff_FS'])\n",
    "variance_score_list = list(['loglike', 'qstat'])\n",
    "\n",
    "# hyperparameters\n",
    "# all individual elements must be individual strings\n",
    "my_hyperparam = dict({\n",
    "    'len_learn_window': '52',\n",
    "    'var_order': '13',\n",
    "    'num_factors': '5',\n",
    "    'forecast_type': '3',\n",
    "    'shock_list': \"dict: {}\".format({\n",
    "        'SPY': '-0.15', 'DIA': '-0.1', 'QQQ': '-0.2'}),\n",
    "    'max_forecast_step': '13',\n",
    "    'target_type': 'Original',\n",
    "    'fwd_cumsum': 'True',\n",
    "    'model_utility': DFM_UTILITY,\n",
    "    'num_forecasts': '13',\n",
    "    'half_life_list': \"list: {}\".format(\n",
    "        half_life_list),\n",
    "    'eval_metric_list': \"list: {}\".format(\n",
    "        eval_metric_list)\n",
    "})\n",
    "\n",
    "# metrics (all individual elements must be individual strings)\n",
    "my_metrics = list()\n",
    "\n",
    "# model_utility = 'timeseries'\n",
    "if my_hyperparam['model_utility'] in ['timeseries']:\n",
    "    for eval_metric in eval_metric_list:\n",
    "        for half_life in half_life_list:\n",
    "            my_metrics.append(dict({\n",
    "                'Name': '{}_#_{}'.format(eval_metric, half_life),\n",
    "                'Regex': '{}_#_{}=(.*?);'.format(eval_metric, half_life)\n",
    "            }))\n",
    "\n",
    "# model_utility = 'volatility'\n",
    "if my_hyperparam['model_utility'] in ['volatility']:\n",
    "    for variance_type in variance_type_list:\n",
    "        for variance_score in variance_score_list:\n",
    "            my_metrics.append(dict({\n",
    "                'Name': '{}_{}'.format(variance_type, variance_score),\n",
    "                'Regex': '{}_{}=(.*?);'.format(variance_type, variance_score)\n",
    "            }))\n",
    "\n",
    "# review\n",
    "print('Hyperparameters: my_hyperparam =')\n",
    "print(my_hyperparam)\n",
    "\n",
    "# review\n",
    "print('\\nEvaluation metrics: my_metrics =')\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an estimator object for running a training job\n",
    "# Information on sagemaker.algorithm.AlgorithmEstimator():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "#\n",
    "my_estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=my_algorithm_arn,\n",
    "    role=my_role,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # volume_size=30,\n",
    "    # volume_kms_key=None,\n",
    "    # max_run=86400,\n",
    "    input_mode='File',\n",
    "    output_path=my_model_path,\n",
    "    # output_kms_key=None,\n",
    "    base_job_name='my-training-job',\n",
    "    sagemaker_session=my_session,\n",
    "    hyperparameters=my_hyperparam,\n",
    "    # tags=None,\n",
    "    # subnets=None,\n",
    "    # security_group_ids=None,\n",
    "    # model_uri=None,\n",
    "    model_channel_name='model',\n",
    "    metric_definitions=my_metrics # ,\n",
    "    # encrypt_inter_container_traffic=False,\n",
    "    # use_spot_instances=False,\n",
    "    # max_wait=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# Information on sagemaker.inputs.TrainingInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "#\n",
    "my_training_input = dict({\n",
    "    training_input_channel:\n",
    "        sagemaker.inputs.TrainingInput(\n",
    "            s3_data=my_input_data_train_path,\n",
    "            # distribution=None,\n",
    "            compression=None,\n",
    "            content_type='text/csv',\n",
    "            # record_wrapping=None,\n",
    "            s3_data_type='S3Prefix',\n",
    "            # instance_groups=None,\n",
    "            input_mode='File' # ,\n",
    "            # attribute_names=None,\n",
    "            # target_attribute_name=None,\n",
    "            # shuffle_config=None\n",
    ")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_training_job, to TRUE, in order to\n",
    "1. run LMDFM model training job\n",
    "1. save model artifacts of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training_job = True | False\n",
    "run_training_job = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_training_job above to TRUE and running model training job in the cell below, you can re-set run_training_job indicator back to FALSE in order to avoid accidentally running model training job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then train the model and save the result\n",
    "if run_training_job and (len(my_trained_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Train the model. Wait for training job completes with information:')\n",
    "    print('Model data of trained model\\n')\n",
    "    \n",
    "    # Information on sagemaker.algorithm.AlgorithmEstimator().fit()\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "    my_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All' # ,\n",
    "        # job_name=None\n",
    "    )\n",
    "    \n",
    "    # model data information\n",
    "    my_trained_model_data = my_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of trained model:')\n",
    "    print(my_trained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information how to visualize metrics during the process, see [Easily monitor and visualize metrics while training models on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/).\n",
    "\n",
    "You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune your model (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Tuning guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and/or forecasting different sets of multiple time-series require different values of hyperparameters: len_learn_window, var_order, and num_factors.\n",
    "\n",
    "Therefore, decisions on specific (integer) values of these hyperparameters need to be made before making meaningful training and inference. There are a variety of commonly practiced methods to estimate the appropriate hyperparameter values. When using AWS Sagemaker, it is natural to use Sagemaker's HyperparameterTuner class to search for appropriate hyperparameter values which result in better forecasts.\n",
    "\n",
    "For information about Automatic model tuning, also see [Perform Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Define tuning configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible ranges of appropriate hyperparameter values depend on specific dataset at hand. For the sample dataset used in this example, a set of reasonable ranges of hyperparameter values are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.IntegerParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "int_hyperpar_range_example = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=52, max_value=157, scaling_type='Auto'),\n",
    "    'var_order':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=52, scaling_type='Auto'),\n",
    "    'num_factors':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=30, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural seasonality of time-series and some \"rule of thumb for choices\" may be utilized to focus on a few reasonable values within reasonable ranges. Following example can be used for a simpler model tuning.\n",
    "\n",
    "For general information about AWS SageMaker Hyperparameter Tuning, referred to [How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) and [Define Hyperparameter Ranges](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.CategoricalParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "my_hyperparam_range = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.CategoricalParameter(['52', '157']),\n",
    "    'var_order':\n",
    "        sagemaker.parameter.CategoricalParameter(['13', '52']),\n",
    "    'num_factors':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=2, max_value=20, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different inference applications need to use different metrics to measure relevant goodness of fit. In this example, we try to forecast future performances of U.S. mutual funds. Proportionalities (a quantifiable version of similarity) between forecasted and realized absolute performances can serve as a useful measure of goodness of fit.\n",
    "\n",
    "If we regard a set of forecasted or realized absolute performances as a multi-dimensional vector, projection of one vector (e.g. forecasted) onto the other (e.g. realized) is a measure of \"proportionality (or similarity) between the two sets of absolute performances\".\n",
    "\n",
    "Therefore, we use the \"projection coefficient\" as the objective metric for tuning the hyperparameters.\n",
    "\n",
    "For general information about AWS SageMaker Metrics, referred to [Define Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available choices for objective tuning metric\n",
    "print('Available model evaulation metrics:')\n",
    "print(my_metrics)\n",
    "\n",
    "# model_utility = 'timeseries'\n",
    "if my_hyperparam['model_utility'] in ['timeseries']:\n",
    "    \n",
    "    # name of objective tuning metric\n",
    "    my_objective_metric = my_metrics[-1]['Name']\n",
    "\n",
    "# model_utility = 'volatility'\n",
    "if my_hyperparam['model_utility'] in ['volatility']:\n",
    "    \n",
    "    # name of objective tuning metric\n",
    "    my_objective_metric = my_metrics[0]['Name']\n",
    "\n",
    "# review\n",
    "print('\\nObjective tuning metric')\n",
    "print(my_objective_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, minimizing error and/or maximizing similarity are desirable tuning directions. Therefore, we will maximize our objective metric, projection coefficient, in this hyperparameter tuning example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direction of hyperparameter optimization\n",
    "my_objective_type = 'Maximize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Run a model tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up hyperparameter tuning job\n",
    "# Information on sagemaker.tuner.HyperparameterTuner():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "#\n",
    "# Notes on an AWS Sagemaker requirement:\n",
    "# when calling the CreateHyperParameterTuningJob operation,\n",
    "# you canâ€™t override the metric definitions for AWS Marketplace algorithms.\n",
    "# try the request without specifying metric definitions.\n",
    "#\n",
    "my_tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=my_estimator,\n",
    "    objective_metric_name=my_objective_metric,\n",
    "    hyperparameter_ranges=my_hyperparam_range,\n",
    "    # metric_definitions=None,\n",
    "    # strategy='Bayesian',\n",
    "    objective_type=my_objective_type,\n",
    "    max_jobs=1,\n",
    "    max_parallel_jobs=1,\n",
    "    # max_runtime_in_seconds=None,\n",
    "    # tags=None,\n",
    "    base_tuning_job_name='my-tuning-job',\n",
    "    # warm_start_config=None,\n",
    "    # strategy_config=None,\n",
    "    # completion_criteria_config=None,\n",
    "    early_stopping_type='Auto' # ,\n",
    "    # estimator_name=None,\n",
    "    # random_seed=None,\n",
    "    # autotune=False,\n",
    "    # hyperparameters_to_keep_static=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_tuning_job, to TRUE, in order to\n",
    "1. run hyperparameter optimization job\n",
    "1. save optimal model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tuning_job = True | False\n",
    "run_tuning_job = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_tuning_job above to TRUE and running hyperparameter tuning job in the cell below, you can re-set run_tuning_job indicator back to FALSE in order to avoid accidentally running hyperparameter tuning job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then optimize model and save the result\n",
    "if run_tuning_job and (len(my_tuned_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Tune the model. Wait for tuning job completes with information:')\n",
    "    print('Model data of tuned model\\n')\n",
    "    \n",
    "    # tuning and waiting\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().fit():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuner.fit(\n",
    "        inputs=my_training_input)\n",
    "    my_tuner.wait()\n",
    "    \n",
    "    # get tuned model and artfacts of the tuned model\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().best_estimator():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuned_estimator = my_tuner.best_estimator()\n",
    "    my_tuned_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All')\n",
    "    \n",
    "    # optimized hyperparameters\n",
    "    my_tuned_hyperparam = my_tuned_estimator.hyperparameters()\n",
    "    \n",
    "    # optimal model artfacts\n",
    "    my_tuned_model_data = my_tuned_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nTuned hyperparameters:')\n",
    "    print(my_tuned_hyperparam)\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of tuned model:')\n",
    "    print(my_tuned_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recommended by AWS Sagemaker Team, once you have completed a tuning job, (or even while the job is still running) you can [clone and use this notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to analyze the results to understand how each hyperparameter effects the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available trained model\n",
    "if len(my_trained_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_trained_model_data\n",
    "    my_model_name = my_trained_model_name\n",
    "\n",
    "# available tuned model\n",
    "if len(my_tuned_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_tuned_model_data\n",
    "    my_model_name = my_tuned_model_name\n",
    "\n",
    "# Information on sagemaker.model.ModelPackage():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_model = sagemaker.model.ModelPackage(\n",
    "    role=my_role,\n",
    "    model_data=my_model_data,\n",
    "    algorithm_arn=my_algorithm_arn, # algorithm arn used to train the model\n",
    "    # algorithm_arn=my_own_algo_name, # OR just the name if your account owns the algorithm\n",
    "    # model_package_arn=None,\n",
    "    # -----------------------\n",
    "    # other **kwargs include:\n",
    "    # image_uri,\n",
    "    # predictor_cls=None,\n",
    "    # env=None,\n",
    "    name=my_model_name,\n",
    "    # vpc_config=None,\n",
    "    sagemaker_session=my_session # ,\n",
    "    # enable_network_isolation=None,\n",
    "    # model_kms_key=None,\n",
    "    # image_config=None,\n",
    "    # source_dir=None,\n",
    "    # code_location=None,\n",
    "    # entry_point=None,\n",
    "    # container_log_level=20,\n",
    "    # dependencies=None,\n",
    "    # git_config=None,\n",
    "    # resources=None\n",
    ")\n",
    "    \n",
    "# review\n",
    "print('Name of model:')\n",
    "print(my_model_name)\n",
    "\n",
    "# review\n",
    "print('\\nArtifacts of model:')\n",
    "print(my_model_data)\n",
    "\n",
    "# review\n",
    "print('\\nModel pacakge')\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Deploy trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Start endpoint for inference. Wait for endpoint becomes ready')\n",
    "\n",
    "# Information on sagemaker.serializers.IdentitySerializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html\n",
    "my_serializer = sagemaker.serializers.IdentitySerializer()\n",
    "\n",
    "# Information on sagemaker.deserializers.StreamDeserializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html\n",
    "my_deserializer = sagemaker.deserializers.StreamDeserializer()\n",
    "\n",
    "# Information on sagemaker.model.Model().deploy():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_endpoint = my_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer,\n",
    "    # accelerator_type=None,\n",
    "    endpoint_name=my_endpoint_name # ,\n",
    "    # tags=None,\n",
    "    # kms_key=None,\n",
    "    # wait=True,\n",
    "    # data_capture_config=None,\n",
    "    # async_inference_config=None,\n",
    "    # serverless_inference_config=None,\n",
    "    # volume_size=None,\n",
    "    # model_data_download_timeout=None,\n",
    "    # container_startup_health_check_timeout=None,\n",
    "    # inference_recommendation_id=None,\n",
    "    # explainer_config=None,\n",
    "    # accept_eula=None,\n",
    "    # endpoint_logging=False\n",
    "    # resources=None,\n",
    "    # endpoint_type=<EndpointType.MODEL_BASED: 'ModelBased'>,\n",
    "    # managed_instance_scaling=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# review\n",
    "print('\\nSagemaker endpoint, ' + my_endpoint_name + ', is now ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "# Information on sagemaker.predictor.Predictor():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=my_endpoint_name,\n",
    "    sagemaker_session=my_session,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer # ,\n",
    "    # component_name=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# review\n",
    "print(my_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input payload can be created by following functions of the class [S3 Utilities](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html)\n",
    "\n",
    "1. **sagemaker.s3.s3_path_join(*args)**: similarly to os.path.join()\n",
    "1. **sagemaker.s3.S3Downloader.read_file(s3_uri, sagemaker_session=None)**: returns the contents of an s3 uri file body as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file for inference\n",
    "my_infer_input_file = sagemaker.s3.s3_path_join(\n",
    "    my_input_data_infer_path,\n",
    "    my_input_data_file)\n",
    "\n",
    "# CSV data: string\n",
    "my_infer_input_str = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_infer_input_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# CSV data: byte stream object\n",
    "my_inference_input_obj = my_infer_input_str.encode()\n",
    "\n",
    "# review\n",
    "print('my_infer_input_file:')\n",
    "print(my_infer_input_file + '\\n')\n",
    "\n",
    "# review\n",
    "print('my_infer_input_str: ' + str(type(my_infer_input_str)))\n",
    "print('my_inference_input_obj: ' + str(type(my_inference_input_obj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().predict():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_forecast = my_predictor.predict(\n",
    "    data=my_inference_input_obj # ,\n",
    "    # initial_args=None,\n",
    "    # target_model=None,\n",
    "    # target_variant=None,\n",
    "    # inference_id=None,\n",
    "    # custom_attributes=None,\n",
    "    # component_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review\n",
    "print('Output of real-time inference:')\n",
    "print(my_forecast)\n",
    "\n",
    "# review\n",
    "# Information on botocore.response.StreamingBody()\n",
    "# https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html\n",
    "print('\\nReal-time forecasts of time-series')\n",
    "print(my_forecast[0].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate it to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utility = 'timeseries'\n",
    "if my_hyperparam['model_utility'] in ['timeseries']:\n",
    "    model_output = 'forecast'\n",
    "    \n",
    "# model_utility = 'volatility'\n",
    "if my_hyperparam['model_utility'] in ['volatility']:\n",
    "    model_output = 'varcov'\n",
    "\n",
    "# default inference ENV variables\n",
    "my_ENV = dict({\n",
    "    'MODELOUTPUT': model_output\n",
    "})\n",
    "\n",
    "# available output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    1\n",
    "]\n",
    "\n",
    "# Information sagemaker.transformer.Transformer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "#\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # strategy=None,\n",
    "    # assemble_with=None,\n",
    "    output_path=my_output_data_infer_path,\n",
    "    # output_kms_key=None,\n",
    "    accept=output_type,\n",
    "    # max_concurrent_transforms=None,\n",
    "    # max_payload=None,\n",
    "    # tags=None,\n",
    "    env=my_ENV,\n",
    "    # base_transform_job_name=None,\n",
    "    sagemaker_session=my_session # ,\n",
    "    # volume_kms_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Batch-transform job input file is located in the S3 folder: {my_bucket}/{my_prefix}/input/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.inputs.TransformInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "my_transform_data_path = my_input_data_infer_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    compression_type=None,\n",
    "    # split_type=None,\n",
    "    # job_name=None,\n",
    "    # input_filter=None,\n",
    "    # output_filter=None, \n",
    "    # join_source=None,\n",
    "    # experiment_config=None,\n",
    "    # model_client_config=None,\n",
    "    # batch_data_capture_config=None,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# review\n",
    "print('Output of batch transform job:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the transform output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"{my_ENV['MODELOUTPUT']}.csv\" = \"forecast.csv\" | \"varcov.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"{my_ENV['MODELOUTPUT']}.json\" = \"forecast.json\" | \"varcov.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Delete the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a batch inference. IF you plan to review the trained or tuned model structure by using Transformer as demonstrated later, do NOT run the cell below. Otherwise, you can delete the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need more batch transform?\n",
    "more_batch_transform = True\n",
    "\n",
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "if not more_batch_transform:\n",
    "    my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model review by using Transformer (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Available LMDFM model output data items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"mean\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "\n",
    "    mean_vec = LMDFM_obj.get_mean()  \n",
    "  \n",
    "    mean_vec : pandas.Series, index (ts_list)  \n",
    "        Sample mean vector of observed vector time-series  \n",
    "            of data points in last learning window  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"stdev\"**  \n",
    "   \n",
    "Data access method and data item(s):  \n",
    "\n",
    "    stdev_vec = LMDFM_obj.get_stdev()  \n",
    "    \n",
    "    stdev_vec : pandas.Series, index (ts_list)\n",
    "        Sample standard deviation vector of observed\n",
    "            vector time-series of data points in last\n",
    "            learning window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"loadings\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "\n",
    "    dfm_loadings, loadings_mat = LMDFM_obj.get_loadings()\n",
    "  \n",
    "    dfm_loadings : dict,\n",
    "                keys (0, 1, ..., var_order, 'DFM-II', 'asof')\n",
    "            obj[key] : pd.DataFrame,\n",
    "                index (ts_list), columns (factor_list)\n",
    "        Loadings matrix of k-lag factors on observed vector\n",
    "            time-series\n",
    "    \n",
    "    loadings_mat : pd.DataFrame,\n",
    "            index (ts_list), columns (factor_list)\n",
    "        Loadings matrix (of DFM Form-II in this LMDFM\n",
    "            algorithm) of (0-lag) common dynamic factors\n",
    "            on observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"factors\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfm_factors = LMDFM_obj.get_factors()\n",
    "    \n",
    "    dfm_factors : pd.DataFrame,\n",
    "            index (factor_list), columns (asof_list)\n",
    "        Row time-series of dynamic factor score column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"common\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vts_common = LMDFM_obj.get_common()\n",
    "    \n",
    "    vts_common : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Common components of Standardized or Zero-mean or\n",
    "            Original value of observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"idiosync\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vts_idiosync = LMDFM_obj.get_idiosync()\n",
    "    \n",
    "    vts_idiosync : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Idiosyncratic components of Standardized or Zero-\n",
    "            mean or Original value of observed vector\n",
    "            time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfmVAR\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    var_dfm = LMDFM_obj.get_dfmVAR()\n",
    "    \n",
    "    var_dfm : dict, keys (1, 2, ..., var_order, 'asof')\n",
    "            obj[k] : pd.DataFrame,\n",
    "                index (factor_list), columns (factor_list)\n",
    "        Vector autoregressive coefficient matrixes of dynamic\n",
    "            common factor score vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"structVAR\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    var_struct = LMDFM_obj.get_structVAR()\n",
    "    \n",
    "    var_struct : dict, keys (0, 1, ..., var_order, 'asof')\n",
    "            obj[k] : pd.DataFrame,\n",
    "                index (factor_list), columns (ts_list)\n",
    "        Structural VAR coefficient matrixes: k-th matrix mapping\n",
    "            k-lag observed data y(t-k) to factor f(t) space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"mtsVAR\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    var_left, var_right = LMDFM_obj.get_mtsVAR()\n",
    "    \n",
    "    var_left : pd.DataFrame,\n",
    "            index (ts_list), columns (factor_list)\n",
    "        Left multiplier of DFM-based VAR model coefficient\n",
    "            matrixes of observed vector time-series\n",
    "    \n",
    "    var_right : dict, keys (1, ..., var_order, 'asof')\n",
    "            obj[k] = var_struct[k] : pd.DataFrame,\n",
    "                index (factor_list), columns (ts_list)\n",
    "        Right multiplier of DFM-based VAR model coefficient\n",
    "            matrixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfsSCov\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_serialcov = LMDFM_obj.get_dfsSCov()  \n",
    "    \n",
    "    dfs_serialcov : dict, keys ((-j, k), ..., 'R', 'asof')\n",
    "                j in [0, 1, 2, ..., var_order]: time lag\n",
    "                k in [0, 1, 2, ..., var_order]: sample lag\n",
    "            obj[(-j, 0)] : pd.Series, index (factor_list)\n",
    "            obj[(-j, k)] : pd.DataFrame,\n",
    "                index / columns (factor_list), k >= 1\n",
    "        Estimated current (j = 0) and past (-j <= -1)\n",
    "            variance vector (k = 0) and k-lag autocovariance\n",
    "            (serial-covariance) matrix (k >= 1) of dynamic\n",
    "            factor score time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"forecast\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_forecast, vts_forecast = LMDFM_obj.get_forecast()\n",
    "    \n",
    "    dfs_forecast : pd.DataFrame, index (factor_list),\n",
    "            columns (1, 2, ..., max_forecast_step, 'asof')\n",
    "        Out-of-sample multi-step forecasts of dynamic factor\n",
    "            scores of observed vector time-series\n",
    "    \n",
    "    vts_forecast : pd.DataFrame, index (ts_list)\n",
    "            columns (1, 2, ..., max_forecast_step, 'asof')\n",
    "        Out-of-sample multi-step forecasts of target_type values\n",
    "            of observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"response\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vts_response = LMDFM_obj.get_response()\n",
    "    \n",
    "    vts_response : pd.DataFrame, index (ts_list)\n",
    "            columns (1, 2, ..., max_forecast_step, 'asof')\n",
    "        Out-of-sample multi-step forecasts of target_type value\n",
    "            of response to impulse or shock vector at time t = asof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"varcov\"**  \n",
    "   \n",
    "Data access method and data item(s):  \n",
    "   \n",
    "    loadings_mat, dfs_variance, idio_variance = (  \n",
    "        LMDFM_obj.get_varcov())  \n",
    "  \n",
    "    loadings_mat : pd.DataFrame,  \n",
    "            index (ts_list), columns (factor_list)  \n",
    "        Loadings matrix of common dynamic factors  \n",
    "            on observed vector time-series  \n",
    "    \n",
    "    dfs_variance : pd.DataFrame, index (factor_list),  \n",
    "            columns (0, 1, ..., max_forecast_step, 'asof')  \n",
    "        Out-of-sample multi-step forecasts of variance vectors  \n",
    "            of dynamic factor score time-series of observed  \n",
    "            vector time-series  \n",
    "    \n",
    "    idio_variance : pd.DataFrame, index (ts_list),  \n",
    "            columns (0, 1, ..., max_forecast_step, 'asof')  \n",
    "        Forecasted variance vector of idiosyncratic component  \n",
    "            time-series of observed vector time-series  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"aggVar\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    agg_variance, agg_variance_comm = LMDFM_obj.get_aggVar()\n",
    "    \n",
    "    agg_variance : pd.Series,\n",
    "            index (0, 1, ..., max_forecast_step, 'asof')\n",
    "        Forecasted variances of aggregate value of target_type\n",
    "            values of observed vector time-series\n",
    "    \n",
    "    agg_variance_comm : pd.Series,\n",
    "            index (0, 1, ..., max_forecast_step, 'asof')\n",
    "        Factor-based common components of forecasted variances\n",
    "            of observed vector time-series, forecasted by common\n",
    "            dynamic factors of all observed time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"indivVar\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    indiv_variance, indiv_variance_comm = LMDFM_obj.get_indivVar()\n",
    "    \n",
    "    indiv_variance : pd.DataFrame,\n",
    "            index (ts_list),\n",
    "            columns (0, 1, ..., max_forecast_step, 'asof')\n",
    "        Forecasted variance vectors of target_type values\n",
    "            of individual observed multiple time-series,\n",
    "            forecasted by common dynamic factors plus\n",
    "            idiosyncratic variances of all observed time-\n",
    "            series\n",
    "    \n",
    "    indiv_variance_comm : pd.DataFrame,\n",
    "            index (ts_list),\n",
    "            columns (0, 1, ..., max_forecast_step, 'asof')\n",
    "        Factor-based common components of forecasted variances\n",
    "            of target_type values of individual observed\n",
    "            multiple time-series, forecasted by common dynamic\n",
    "            factors of all observed time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vcMatrix\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    comm_varcov, idio_variance, vts_varcov = LMDFM_obj.get_vcMatrix()\n",
    "    \n",
    "    comm_varcov : dict,\n",
    "                keys (0, 1, ..., max_forecast_step, 'asof')\n",
    "            obj[key] : pd.DataFrame,\n",
    "                index (ts_list), columns (ts_list)\n",
    "        Forecasted variance-covariance matrix of factor-based\n",
    "            common component time-series of observed vector\n",
    "            time-series\n",
    "    \n",
    "    idio_variance : pd.DataFrame, index (ts_list),\n",
    "            columns (0, 1, ..., max_forecast_step, 'asof')\n",
    "        Forecasted variance vector of idiosyncratic component\n",
    "            time-series of observed vector time-series\n",
    "    \n",
    "    vts_varcov : dict,\n",
    "                keys (0, 1, ..., max_forecast_step, 'asof')\n",
    "            obj[key] : pd.DataFrame,\n",
    "                index (ts_list), columns (ts_list)\n",
    "        Forecasted variance-covariance matrix of observed\n",
    "            vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfsACov\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_autocov = LMDFM_obj.get_dfsACov()\n",
    "    \n",
    "    dfs_autocov : dict, keys ((s, k), ..., 'R', 'asof')\n",
    "                s in [0, 1, ..., mx_forec_stp]: forec step\n",
    "                k in [0, 1, 2, ..., var_order]: sample lag\n",
    "            obj[(j, 0)] : pd.Series, index (factor_list)\n",
    "            obj[(j, k)] : pd.DataFrame,\n",
    "                index / columns (factor_list), k >= 1\n",
    "        Forecasted (s >= 1) variance vector (k = 0) and\n",
    "            k-lag autocovariance matrix (k >= 1) of dynamic\n",
    "            factor score time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Select LMDFM model output data item for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained or tuned YWpcAR model structure can be reviewed item by item using Transformer with specific value of environment variable, my_ENV['MODELOUTPUT']  \n",
    "  \n",
    "Choices of value of the environment variable are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utility = 'timeseries'\n",
    "if my_hyperparam['model_utility'] in ['timeseries']:\n",
    "    model_output_choice = dict({\n",
    "         1: 'mean',\n",
    "         2: 'stdev',\n",
    "         3: 'loadings',\n",
    "         4: 'factors',\n",
    "         5: 'common',\n",
    "         6: 'idiosync',\n",
    "         7: 'dfmVAR',\n",
    "         8: 'structVAR',\n",
    "         9: 'mtsVAR',\n",
    "        # 10: 'dfsSCov',\n",
    "        11: 'forecast',\n",
    "        12: 'response',\n",
    "        # 13: 'varcov',\n",
    "        # 14: 'aggVar',\n",
    "        # 15: 'indivVar',\n",
    "        # 16: 'vcMatrix',\n",
    "        # 17: 'dfsACov'\n",
    "    })\n",
    "\n",
    "# model_utility = 'volatility'\n",
    "if my_hyperparam['model_utility'] in ['volatility']:\n",
    "    model_output_choice = dict({\n",
    "        #  1: 'mean',\n",
    "        #  2: 'stdev',\n",
    "        #  3: 'loadings',\n",
    "        #  4: 'factors',\n",
    "        #  5: 'common',\n",
    "        #  6: 'idiosync',\n",
    "        #  7: 'dfmVAR',\n",
    "        #  8: 'structVAR',\n",
    "        #  9: 'mtsVAR',\n",
    "        10: 'dfsSCov',\n",
    "        # 11: 'forecast',\n",
    "        # 12: 'response',\n",
    "        13: 'varcov',\n",
    "        14: 'aggVar',\n",
    "        15: 'indivVar',\n",
    "        16: 'vcMatrix',\n",
    "        17: 'dfsACov'\n",
    "    })\n",
    "\n",
    "# available choices for output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make any valid pair of choices as exemplified as in following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utility = 'timeseries'\n",
    "if my_hyperparam['model_utility'] in ['timeseries']:\n",
    "    model_output = model_output_choice[\n",
    "        7\n",
    "    ]\n",
    "\n",
    "# model_utility = 'volatility'\n",
    "if my_hyperparam['model_utility'] in ['volatility']:\n",
    "    model_output = model_output_choice[\n",
    "        16\n",
    "    ]\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    1\n",
    "]\n",
    "\n",
    "# review\n",
    "print('model_output = ' + model_output)\n",
    "print('output_type = ' + output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Model structure review with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV variables\n",
    "my_ENV = dict({\n",
    "    'MODELOUTPUT': model_output})\n",
    "\n",
    "# sagemaker.transformer.Transformer()\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "#\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # strategy=None,\n",
    "    # assemble_with=None,\n",
    "    output_path=my_output_data_infer_path,\n",
    "    # output_kms_key=None,\n",
    "    accept=output_type,\n",
    "    # max_concurrent_transforms=None,\n",
    "    # max_payload=None,\n",
    "    # tags=None,\n",
    "    env=my_ENV,\n",
    "    # base_transform_job_name=None,\n",
    "    sagemaker_session=my_session # ,\n",
    "    # volume_kms_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.inputs.TransformInput()\n",
    "my_transform_data_path = my_input_data_infer_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'\n",
    "\n",
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    compression_type=None,\n",
    "    # split_type=None,\n",
    "    # job_name=None,\n",
    "    # input_filter=None,\n",
    "    # output_filter=None, \n",
    "    # join_source=None,\n",
    "    # experiment_config=None,\n",
    "    # model_client_config=None,\n",
    "    # batch_data_capture_config=None,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# display\n",
    "print('Selected output:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the selected output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"{my_ENV['MODELOUTPUT']}.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"{my_ENV['MODELOUTPUT']}.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Delete endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:  \n",
    "\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
