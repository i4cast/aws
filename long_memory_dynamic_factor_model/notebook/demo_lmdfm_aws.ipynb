{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, deploy and review machine learning algorithm/model LMDFM (Long-Nemory Dynamic Factor Model) from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Overview of the algorithm  \n",
    "  \n",
    "The Long-Memory Dynamic Factor Model (LMDFM) is a non-stationary (or time-varying) DFM. All model coefficients and outputs are estimated by an implementation of \"spectral principal components analysis\" (spectral PCA) with “conjugate two-dimensional discrete Fourier transform” (C2D-DFT). This estimation method is detailed in [\"Introduction to Non-Stationary Dynamic Factor Models Estimated by Spectral PCA with Conjugate 2D-DFT\"](https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/publication/Non-stationary_DFMs_estimated_by_spectral_PCA_and_conjugate_2D-DFT.pdf).\n",
    "  \n",
    "The LMDFM algorithm is to make (1) dynamic factor analysis of observed multiple (vector) time-series, (2) multi-step multivariate forecasts of vector time-series, and (3) multi-step forecasts of multivariate volatility (variance-covariance) of vector time-series. \n",
    "  \n",
    "The LMDFM algorithm estimates (a) dynamic factor loadings matrixes, (b) vector autoregressive (VAR) coefficients of dynamic factors, (c) variances and vector autocovariances of dynamic factors, and (d) variances of several stochastic components. \n",
    "  \n",
    "The LMDFM is developed for modeling, analyzing and forecasting large number of time-series in big vector time-series datasets.\n",
    "  \n",
    "WHY Non-Stationary DFMs?\n",
    "1. Structures and values of datasets choose models needed.\n",
    "1. Big datasets of large number of observed time-series with smaller number of underlying sources of influences commonly affecting all or many time-series: Factor Models.\n",
    "1. Having causal relationships with a range of time lags among time-series and common factors: Dynamic models.\n",
    "1. Underlying relationships modeled among data points change and evolve over time: Non-Stationary models.\n",
    "1. All of the above: Non-Stationary Dynamic Factor Models (non-stationary DFMs).\n",
    "  \n",
    "WHY Spectral PCA with C2D-DFT?\n",
    "1. Modeling objectives choose estimation methods.\n",
    "1. DFM to model big-datasets of large number of time-series: principal components analysis (PCA).\n",
    "1. Limited length of observed (large number of) dynamic time-series distorted by stochastic noises: Spectral PCA.\n",
    "1. Non-stationary (time varying) modeling utilizing covariances with two-dimensional time-lags: two-dimensional discrete Fourier transform (2D-DFT).\n",
    "1. Needs of Hermitian matrix for spectral PCA: Conjugate 2D-DFT (C2D-DFT).\n",
    "1. All of the above: Spectral PCA with C2D-DFT.\n",
    "  \n",
    "WHY Both Time-Series Forecasts and Covariance Forecasts?\n",
    "1. Features of analysis choose companion analysis.\n",
    "1. Uncertainty in time-series forecasts: volatility (variance/covariance) forecasts.\n",
    "1. Non-stationarity in volatility forecasts: time-series forecasts.\n",
    "1. Intrinsic relationships between time-series and volatilities: modeling and forecasting both by same models.\n",
    "1. Examples of datasets: measurements and indicators of multinational economies, prices of things constantly traded in markets, measurements of natural or engineering processes, social or political trends, scores of sports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Academic publications on dynamic factor models (DFMs)\n",
    "  \n",
    "M. Barigozzi  (2024).  “Dynamic Factor Models”.  Università di Bologna, October 2024.  https://www.barigozzi.eu/MB_DFM_complete_slides.pdf.\n",
    "  \n",
    "C. Doz  and  P. Fuleky  (2020).  \"Chapter 2,  Dynamic Factor Models\" in Macroeconomic Forecasting in the Era of Big Data: Theory and Practice, Ed. P. Fuleky,  Advanced Studies in Theoretical and Applied Econometrics, Volume 52.  Springer.  https://www.springer.com/gp/book/9783030311490 or manuscript https://halshs.archives-ouvertes.fr/halshs-02262202/document.  \n",
    "  \n",
    "i4cast LLC  (2025).  \"Introduction to Non-Stationary Dynamic Factor Models Estimated by Spectral PCA with Conjugate 2D-DFT\".  https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/publication/Non-stationary_DFMs_estimated_by_spectral_PCA_and_conjugate_2D-DFT.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook\n",
    "\n",
    "This sample notebook shows you how to train, tune, deploy and understand a custom ML algorithm/model: [Long-Memory Dynamic Factor Model (LMDFM)](https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa), guided by common practices to [Use Algorithm and Model Package Resources](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-buy.html).\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    1. or your AWS account has a subscription to [Long-Memory Dynamic Factor Model (LMDFM)](https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "    1. [Subscription](#1.1.-Subscription)\n",
    "    1. [Prepare relevant environment](#1.2.-Prepare-relevant-environment)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "    1. [Dataset format expected by the algorithm](#2.1.-Dataset-format-expected-by-the-algorithm)\n",
    "    1. [Configure and visualize training dataset](#2.2.-Configure-and-visualize-training-dataset)\n",
    "    1. [Upload datasets to Amazon S3](#2.3.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3.-Train-a-machine-learning-model)\n",
    "    1. [Set hyperparameters](#3.1.-Set-hyperparameters)\n",
    "    1. [Train a model](#3.2.-Train-a-model)\n",
    "1. [Tune your model (optional)](#4.-Tune-your-model-(optional))\n",
    "    1. [Tuning Guidelines](#4.1.-Tuning-guidelines)\n",
    "    1. [Define Tuning configuration](#4.2.-Define-tuning-configuration)\n",
    "    1. [Run a model tuning job](#4.3.-Run-a-model-tuning-job)\n",
    "1. [Deploy model and verify results](#5.-Deploy-model-and-verify-results)\n",
    "    1. [Trained or tuned model](#5.1.-Trained-or-tuned-model)\n",
    "    1. [Deploy trained or tuned model](#5.2.-Deploy-trained-or-tuned-model)\n",
    "    1. [Create input payload](#5.3.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#5.4.-Perform-real-time-inference)\n",
    "1. [Perform Batch inference](#6.-Perform-batch-inference)\n",
    "    1. [Batch transform](#6.1.-Batch-transform)\n",
    "    1. [Delete the model](#6.2.-Delete-the-model)\n",
    "1. [Model review by using Transformer (optional)](#7.-Model-review-by-using-Transformer-(optional))\n",
    "    1. [Available LMDFM model output data items](#7.1.-Available-LMDFM-model-output-data-items)\n",
    "    1. [Select LMDFM model output data item for review](#7.2.-Select-LMDFM-model-output-data-item-for-review)\n",
    "    1. [Model structure review with Transformer](#7.3.-Model-structure-review-with-Transformer)\n",
    "1. [Clean-up](#8.-Clean-up)\n",
    "    1. [Delete endpoint and model](#8.1.-Delete-endpoint-and-model)\n",
    "    1. [Unsubscribe to the listing (optional)](#8.2.-Unsubscribe-to-the-listing-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage instructions\n",
    "\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sagemaker Notebook\n",
    "\n",
    "For readers who like to review how to use Sagemaker Notebook in general, following Sagemaker documentation pages are best resources.  \n",
    "    [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)  \n",
    "    [Step 1: Create an Amazon SageMaker Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)  \n",
    "    [Step 2: Create a Jupyter Notebook](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-prepare.html)  \n",
    "    [Step 3: Download, Explore, and Transform a Dataset](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-preprocess-data.html)  \n",
    "    [Step 4: Train a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-train-model.html)  \n",
    "    [Step 5: Deploy the Model to Amazon EC2](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-model-deployment.html)  \n",
    "    [Step 6: Evaluate the Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-test-model.html)  \n",
    "    [Step 7: Clean Up](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "\n",
    "1. Open the algorithm listing page, [Long-Memory Dynamic Factor Model (LMDFM)](\n",
    "https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your valid algorithm ARN\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{region}:123456789012:algorithm/{lmdfm_algorithm}'\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{}:{}:algorithm/{}'.format(\n",
    "#     'your_region', 'your_aws_account_number', 'your_lmdfm_algorithm_label')\n",
    "my_algorithm_arn = 'arn:aws:sagemaker:us-east-1:123456789012:algorithm/...'\n",
    "my_prefix = 'lmdfm'\n",
    "\n",
    "# LMDFM algorithm/model training/inference plan\n",
    "# ----------------------------------------\n",
    "# to focus on time-series forecast\n",
    "tuning_plan = 'timeseries'\n",
    "# ----------------------------------------\n",
    "# to focus on volatility forecast\n",
    "# tuning_plan = 'volatility'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Prepare relevant environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "# remind\n",
    "print('Wait for Sagemaker values assigned to TWO important variables: my_bucket and my_role.\\n')\n",
    "\n",
    "# sagemaker session\n",
    "my_session = sagemaker.session.Session()\n",
    "\n",
    "# sagemaker attributes\n",
    "my_bucket = my_session.default_bucket()\n",
    "my_role = sagemaker.session.get_execution_role()\n",
    "\n",
    "# review\n",
    "print('my_bucket = {}'.format(my_bucket))\n",
    "print('my_role = {}'.format(my_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this Sagemaker machine learning ('ml') notebook example, following S3 folders are expected to be in place:\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. {my_bucket}/{my_prefix}/model/\n",
    "1. {my_bucket}/{my_prefix}/output/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 paths\n",
    "my_input_data_train_path = 's3://{}/{}/input/data/train'.format(my_bucket, my_prefix)\n",
    "my_input_data_infer_path = 's3://{}/{}/input/data/inference'.format(my_bucket, my_prefix)\n",
    "my_model_path = 's3://{}/{}/model'.format(my_bucket, my_prefix)\n",
    "my_output_data_infer_path = 's3://{}/{}/output/data/inference'.format(my_bucket, my_prefix)\n",
    "\n",
    "# lmdfm Docker container training channel\n",
    "training_input_channel = 'train'\n",
    "\n",
    "# aws computing instance type: 'ml.m5.xlarge'\n",
    "my_EC2 = 'ml.m5.xlarge'\n",
    "\n",
    "# input CSV data file name\n",
    "my_input_data_file = 'Weekly_VTS_6Yr.csv'\n",
    "\n",
    "# information available model and endpoint\n",
    "my_model_data = str()  # to be assigned / defined\n",
    "my_model_name = str()  # to be assigned / defined \n",
    "my_endpoint_name = 'my-endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are revisiting this demo notebook, and your model training job and/or your hyperparameter tuning job (to be defined later) were already run at least once, you can copy the resulted Sagemaker string values of your trained model data path and/or your tuned model data path to the variables, my_trained_model_data and/or my_tuned_model_data, in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model placeholder\n",
    "# my_trained_model_data = str()\n",
    "my_trained_model_data = str()\n",
    "my_trained_model_name = 'my-trained-model'\n",
    "\n",
    "# tuned model placeholder\n",
    "# my_tuned_model_data = str()\n",
    "my_tuned_model_data = str()\n",
    "my_tuned_model_name = 'my-tuned-model'\n",
    "\n",
    "# tuning_plan = 'timeseries'\n",
    "if tuning_plan in ['timeseries']:\n",
    "    \n",
    "    # AVAILABLE Model data of trained model\n",
    "    # IF model is trained and not to be trained again, copy-paste or type the full model data path for my_trained_model_data\n",
    "    # my_trained_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_trained_model_data = (\n",
    "        '')\n",
    "    \n",
    "    # AVAILABLE Model data of tuned model\n",
    "    # IF model is tuned and not to be tuned again, copy-paste or type the full model data path for my_tuned_model_data\n",
    "    # my_tuned_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_tuned_model_data = (\n",
    "        '')\n",
    "\n",
    "# tuning_plan = 'volatility'\n",
    "if tuning_plan in ['volatility']:\n",
    "    \n",
    "    # AVAILABLE Model data of trained model\n",
    "    # IF model is trained and not to be trained again, copy-paste or type the full model data path for my_trained_model_data\n",
    "    # my_trained_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_trained_model_data = (\n",
    "        '')\n",
    "    \n",
    "    # AVAILABLE Model data of tuned model\n",
    "    # IF model is tuned and not to be tuned again, copy-paste or type the full model data path for my_tuned_model_data\n",
    "    # my_tuned_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "    my_tuned_model_data = (\n",
    "        '')\n",
    "\n",
    "# review\n",
    "print('Model data of trained model:')\n",
    "print(my_trained_model_data)\n",
    "print('Name of trained model:')\n",
    "print(my_trained_model_name)\n",
    "\n",
    "# review\n",
    "print('\\nModel data of tuned model:')\n",
    "print(my_tuned_model_data)\n",
    "print('Name of tuned model:')\n",
    "print(my_tuned_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LMDFM (long-memory dynamic factor model) algorithm takes, as input data,\n",
    "multiple time-series data contained in a CSV (comma separated value) data table, in a format of a CSV text-string or a CSV text-file.\n",
    "\n",
    "Each row of the data table is for values of an individual time-series (TS). Row header is the label or symbol of the time-series.\n",
    "Each column is for values of all time-series at a specific moment in time. Column header is the time-index or time-stamp of the moment.\n",
    "The first data column is for the earliest time and the last column for the most recent time.\n",
    "Therefore, the first row of the CSV data table is \"Label/Symbol/Description, earliest time-stamp, next time-stamp, ..., most recent time-stamp\".\n",
    "The first column of the CSV table is \"Label/Symbol/Description, label of 1st TS, label of 2nd TS, ..., label of last TS\".\n",
    "The current version of LMDFM requires equally spaced time-stamps.\n",
    "\n",
    "Since LMDFM forecasts future values of multiple time-series using \"Vector Autoregressive (VAR)\" model estimated by \"Dynamic Factor Model (DFM)\",\n",
    "the input data is essentially in the form of \"Row Time-Series of Column Vector\".\n",
    "\n",
    "One of the simplest methods to generate such a CSV text-file is to save a Microsoft Excel spreadsheet as (into) a CSV file.\n",
    "\n",
    "You can also find more information about dataset format in **Usage Information** section of \n",
    "[Long-Memory Dynamic Factor Model (LMDFM)](\n",
    "https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Configure and visualize training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [sample data](https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/input/Weekly_VTS_6Yr.csv) provided with this product/example is six-year weekly (logarithmic) performances of mutual funds traded in the U.S. invested in equities, fixed income, and commodities. Each row is of an individual mutual fund. Each column is of a specific calendar week in history. The last week (the last column) was the week with a time-stamp as \"2021-12-31\". Following simple steps you can upload this sample data to your S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the sample dataset from https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/input/Weekly_VTS_6Yr.csv, and then upload the dataset to\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/ for training\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/ for inference\n",
    "\n",
    "following simple steps can be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open webpage https://github.com/i4cast/aws/blob/main/long_memory_dynamic_factor_model/input/Weekly_VTS_6Yr.csv\n",
    "1. Click [Raw] option located at top right of the data table\n",
    "1. In the Raw data window, right click [Save as]\n",
    "1. Set local file folder and file name in the \"Save As\" window, then click [Save]\n",
    "\n",
    "1. Open AWS S3 Console\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. Upload the saved local data file to your AWS S3 folder\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. Upload the saved local data file to your AWS S3 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about dataset format in **Hyperparameters** section of [Long-Memory Dynamic Factor Model (LMDFM)](https://aws.amazon.com/marketplace/pp/prodview-da6ffrp4mlopg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half_life_list and eval_metric_list\n",
    "half_life_list = ['13', '26', '52']\n",
    "eval_metric_list = ['projection_coefficient']\n",
    "\n",
    "# variance_type_list and variance_score_list\n",
    "variance_type_list = list(['diff_FN', 'diff_FS'])\n",
    "variance_score_list = list(['loglike', 'qstat'])\n",
    "\n",
    "# hyperparameters\n",
    "# all individual elements must be individual strings\n",
    "my_hyperparam = dict({\n",
    "    'len_learn_window': '52',\n",
    "    'var_order': '13',\n",
    "    'num_factors': '5',\n",
    "    # 'ldgs_order': '13',\n",
    "    # 'dfs_order': '13',\n",
    "    'forecast_type': 'FOMS',\n",
    "    'shock_list': \"dict: {}\".format(\n",
    "        {'SPY': '-1.0', 'DIA': '-1.0', 'QQQ': '-1.0'}),\n",
    "    'max_forecast_step': '13',\n",
    "    'target_type': 'Original',\n",
    "    'fwd_cumsum': 'True',\n",
    "    'num_forecasts': '13',\n",
    "    'half_life_list': \"list: {}\".format(\n",
    "        half_life_list),\n",
    "    'eval_metric_list': \"list: {}\".format(\n",
    "        eval_metric_list)\n",
    "})\n",
    "\n",
    "# metrics (all individual elements must be individual strings)\n",
    "my_metrics = list()\n",
    "\n",
    "# tuning_plan = 'timeseries'\n",
    "if tuning_plan in ['timeseries']:\n",
    "    for eval_metric in eval_metric_list:\n",
    "        for half_life in half_life_list:\n",
    "            my_metrics.append(dict({\n",
    "                'Name': '{}_#_{}'.format(eval_metric, half_life),\n",
    "                'Regex': '{}_#_{}=(.*?);'.format(eval_metric, half_life)\n",
    "            }))\n",
    "\n",
    "# tuning_plan = 'volatility'\n",
    "if tuning_plan in ['volatility']:\n",
    "    for variance_type in variance_type_list:\n",
    "        for variance_score in variance_score_list:\n",
    "            my_metrics.append(dict({\n",
    "                'Name': '{}_{}'.format(variance_type, variance_score),\n",
    "                'Regex': '{}_{}=(.*?);'.format(variance_type, variance_score)\n",
    "            }))\n",
    "\n",
    "# review\n",
    "print('Hyperparameters: my_hyperparam =')\n",
    "print(my_hyperparam)\n",
    "\n",
    "# review\n",
    "print('\\nEvaluation metrics: my_metrics =')\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an estimator object for running a training job\n",
    "# Information on sagemaker.algorithm.AlgorithmEstimator():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "#\n",
    "my_estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=my_algorithm_arn,\n",
    "    role=my_role,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # volume_size=30,\n",
    "    # volume_kms_key=None,\n",
    "    # max_run=86400,\n",
    "    input_mode='File',\n",
    "    output_path=my_model_path,\n",
    "    # output_kms_key=None,\n",
    "    base_job_name='my-training-job',\n",
    "    sagemaker_session=my_session,\n",
    "    hyperparameters=my_hyperparam,\n",
    "    # tags=None,\n",
    "    # subnets=None,\n",
    "    # security_group_ids=None,\n",
    "    # model_uri=None,\n",
    "    model_channel_name='model',\n",
    "    metric_definitions=my_metrics\n",
    "    # ,\n",
    "    # encrypt_inter_container_traffic=False,\n",
    "    # use_spot_instances=False,\n",
    "    # max_wait=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# Information on sagemaker.inputs.TrainingInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "#\n",
    "my_training_input = dict({\n",
    "    training_input_channel:\n",
    "        sagemaker.inputs.TrainingInput(\n",
    "            s3_data=my_input_data_train_path,\n",
    "            # distribution=None,\n",
    "            compression=None,\n",
    "            content_type='text/csv',\n",
    "            # record_wrapping=None,\n",
    "            s3_data_type='S3Prefix',\n",
    "            # instance_groups=None,\n",
    "            input_mode='File' # ,\n",
    "            # attribute_names=None,\n",
    "            # target_attribute_name=None,\n",
    "            # shuffle_config=None\n",
    ")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_training_job, to TRUE, in order to\n",
    "1. run LMDFM model training job\n",
    "1. save model artifacts of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training_job = True | False\n",
    "run_training_job = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_training_job above to TRUE and running model training job in the cell below, you can re-set run_training_job indicator back to FALSE in order to avoid accidentally running model training job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then train the model and save the result\n",
    "if run_training_job and (len(my_trained_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Train the model. Wait for training job completes with information:')\n",
    "    print('Model data of trained model\\n')\n",
    "    \n",
    "    # Information on sagemaker.algorithm.AlgorithmEstimator().fit()\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "    my_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All'\n",
    "        # ,\n",
    "        # job_name=None\n",
    "    )\n",
    "    \n",
    "    # model data information\n",
    "    my_trained_model_data = my_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of trained model:')\n",
    "    print(my_trained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information how to visualize metrics during the process, see [Easily monitor and visualize metrics while training models on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/).\n",
    "\n",
    "You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune your model (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Tuning guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and/or forecasting different sets of multiple time-series require different values of hyperparameters: len_learn_window, var_order, and num_factors.\n",
    "\n",
    "Therefore, decisions on specific (integer) values of these hyperparameters need to be made before making meaningful training and inference. There are a variety of commonly practiced methods to estimate the appropriate hyperparameter values. When using AWS Sagemaker, it is natural to use Sagemaker's HyperparameterTuner class to search for appropriate hyperparameter values which result in better forecasts.\n",
    "\n",
    "For information about Automatic model tuning, also see [Perform Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Define tuning configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible ranges of appropriate hyperparameter values depend on specific dataset at hand. For the sample dataset used in this example, a set of reasonable ranges of hyperparameter values are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.IntegerParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "int_hyperpar_range_example = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=52, max_value=157, scaling_type='Auto'),\n",
    "    'var_order':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=52, scaling_type='Auto'),\n",
    "    'num_factors':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=30, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural seasonality of time-series and some \"rule of thumb for choices\" may be utilized to focus on a few reasonable values within reasonable ranges. Following example can be used for a simpler model tuning.\n",
    "\n",
    "For general information about AWS SageMaker Hyperparameter Tuning, referred to [How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) and [Define Hyperparameter Ranges](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.CategoricalParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "my_hyperparam_range = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.CategoricalParameter(['52', '157']),\n",
    "    'var_order':\n",
    "        sagemaker.parameter.CategoricalParameter(['13', '52']),\n",
    "    'num_factors':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=2, max_value=20, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different inference applications need to use different metrics to measure relevant goodness of fit. In this example, we try to forecast future performances of U.S. mutual funds. Proportionalities (a quantifiable version of similarity) between forecasted and realized absolute performances can serve as a useful measure of goodness of fit.\n",
    "\n",
    "If we regard a set of forecasted or realized absolute performances as a multi-dimensional vector, projection of one vector (e.g. forecasted) onto the other (e.g. realized) is a measure of \"proportionality (or similarity) between the two sets of absolute performances\".\n",
    "\n",
    "Therefore, we use the \"projection coefficient\" as the objective metric for tuning the hyperparameters.\n",
    "\n",
    "For general information about AWS SageMaker Metrics, referred to [Define Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available choices for objective tuning metric\n",
    "print('Available model evaulation metrics:')\n",
    "print(my_metrics)\n",
    "\n",
    "# tuning_plan = 'timeseries'\n",
    "if tuning_plan in ['timeseries']:\n",
    "    \n",
    "    # name of objective tuning metric\n",
    "    my_objective_metric = my_metrics[-1]['Name']\n",
    "\n",
    "# tuning_plan = 'volatility'\n",
    "if tuning_plan in ['volatility']:\n",
    "    \n",
    "    # name of objective tuning metric\n",
    "    my_objective_metric = my_metrics[0]['Name']\n",
    "\n",
    "# review\n",
    "print('\\nObjective tuning metric')\n",
    "print(my_objective_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, minimizing error and/or maximizing similarity are desirable tuning directions. Therefore, we will maximize our objective metric, projection coefficient, in this hyperparameter tuning example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direction of hyperparameter optimization\n",
    "my_objective_type = 'Maximize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Run a model tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up hyperparameter tuning job\n",
    "# Information on sagemaker.tuner.HyperparameterTuner():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "#\n",
    "# Notes on an AWS Sagemaker requirement:\n",
    "# when calling the CreateHyperParameterTuningJob operation,\n",
    "# you can’t override the metric definitions for AWS Marketplace algorithms.\n",
    "# try the request without specifying metric definitions.\n",
    "#\n",
    "my_tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=my_estimator,\n",
    "    objective_metric_name=my_objective_metric,\n",
    "    hyperparameter_ranges=my_hyperparam_range,\n",
    "    # metric_definitions=None,\n",
    "    # strategy='Bayesian',\n",
    "    objective_type=my_objective_type,\n",
    "    max_jobs=1,\n",
    "    max_parallel_jobs=1,\n",
    "    # max_runtime_in_seconds=None,\n",
    "    # tags=None,\n",
    "    base_tuning_job_name='my-tuning-job',\n",
    "    # warm_start_config=None,\n",
    "    # strategy_config=None,\n",
    "    # completion_criteria_config=None,\n",
    "    early_stopping_type='Auto'\n",
    "    # ,\n",
    "    # estimator_name=None,\n",
    "    # random_seed=None,\n",
    "    # autotune=False,\n",
    "    # hyperparameters_to_keep_static=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_tuning_job, to TRUE, in order to\n",
    "1. run hyperparameter optimization job\n",
    "1. save optimal model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tuning_job = True | False\n",
    "run_tuning_job = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_tuning_job above to TRUE and running hyperparameter tuning job in the cell below, you can re-set run_tuning_job indicator back to FALSE in order to avoid accidentally running hyperparameter tuning job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then optimize model and save the result\n",
    "if run_tuning_job and (len(my_tuned_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Tune the model. Wait for tuning job completes with information:')\n",
    "    print('Model data of tuned model\\n')\n",
    "    \n",
    "    # tuning and waiting\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().fit():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuner.fit(\n",
    "        inputs=my_training_input)\n",
    "    my_tuner.wait()\n",
    "    \n",
    "    # get tuned model and artfacts of the tuned model\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().best_estimator():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuned_estimator = my_tuner.best_estimator()\n",
    "    my_tuned_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All')\n",
    "    \n",
    "    # optimized hyperparameters\n",
    "    my_tuned_hyperparam = my_tuned_estimator.hyperparameters()\n",
    "    \n",
    "    # optimal model artfacts\n",
    "    my_tuned_model_data = my_tuned_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nTuned hyperparameters:')\n",
    "    print(my_tuned_hyperparam)\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of tuned model:')\n",
    "    print(my_tuned_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recommended by AWS Sagemaker Team, once you have completed a tuning job, (or even while the job is still running) you can [clone and use this notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to analyze the results to understand how each hyperparameter effects the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available trained model\n",
    "if len(my_trained_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_trained_model_data\n",
    "    my_model_name = my_trained_model_name\n",
    "\n",
    "# available tuned model\n",
    "if len(my_tuned_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_tuned_model_data\n",
    "    my_model_name = my_tuned_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning_plan = 'timeseries'\n",
    "if tuning_plan in ['timeseries']:\n",
    "    model_output = 'forecast'\n",
    "    \n",
    "# tuning_plan = 'volatility'\n",
    "if tuning_plan in ['volatility']:\n",
    "    model_output = 'vcf_component'\n",
    "\n",
    "# default inference ENV variables\n",
    "my_ENV = dict({\n",
    "    'MODELOUTPUT': model_output\n",
    "})\n",
    "\n",
    "# available output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.model.ModelPackage():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_model = sagemaker.model.ModelPackage(\n",
    "    role=my_role,\n",
    "    model_data=my_model_data,\n",
    "    algorithm_arn=my_algorithm_arn, # algorithm arn used to train the model\n",
    "    # algorithm_arn=my_own_algo_name, # OR just the name if your account owns the algorithm\n",
    "    # model_package_arn=None,\n",
    "    # -----------------------\n",
    "    # other **kwargs include:\n",
    "    # image_uri,\n",
    "    # predictor_cls=None,\n",
    "    env=my_ENV,\n",
    "    name=my_model_name,\n",
    "    # vpc_config=None,\n",
    "    sagemaker_session=my_session\n",
    "    # ,\n",
    "    # enable_network_isolation=None,\n",
    "    # model_kms_key=None,\n",
    "    # image_config=None,\n",
    "    # source_dir=None,\n",
    "    # code_location=None,\n",
    "    # entry_point=None,\n",
    "    # container_log_level=20,\n",
    "    # dependencies=None,\n",
    "    # git_config=None,\n",
    "    # resources=None\n",
    ")\n",
    "    \n",
    "# review\n",
    "print('Name of model:')\n",
    "print(my_model_name)\n",
    "\n",
    "# review\n",
    "print('\\nArtifacts of model:')\n",
    "print(my_model_data)\n",
    "\n",
    "# review\n",
    "print('\\nModel pacakge')\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Deploy trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Start endpoint for inference. Wait for endpoint becomes ready')\n",
    "\n",
    "# Information on sagemaker.serializers.IdentitySerializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html\n",
    "my_serializer = sagemaker.serializers.IdentitySerializer()\n",
    "\n",
    "# Information on sagemaker.deserializers.StreamDeserializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html\n",
    "my_deserializer = sagemaker.deserializers.StreamDeserializer()\n",
    "\n",
    "# Information on sagemaker.model.Model().deploy():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_endpoint = my_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer,\n",
    "    # accelerator_type=None,\n",
    "    endpoint_name=my_endpoint_name\n",
    "    # ,\n",
    "    # tags=None,\n",
    "    # kms_key=None,\n",
    "    # wait=True,\n",
    "    # data_capture_config=None,\n",
    "    # async_inference_config=None,\n",
    "    # serverless_inference_config=None,\n",
    "    # volume_size=None,\n",
    "    # model_data_download_timeout=None,\n",
    "    # container_startup_health_check_timeout=None,\n",
    "    # inference_recommendation_id=None,\n",
    "    # explainer_config=None,\n",
    "    # accept_eula=None,\n",
    "    # endpoint_logging=False\n",
    "    # resources=None,\n",
    "    # endpoint_type=<EndpointType.MODEL_BASED: 'ModelBased'>,\n",
    "    # managed_instance_scaling=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# review\n",
    "print('\\nSagemaker endpoint, ' + my_endpoint_name + ', is now ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "# Information on sagemaker.predictor.Predictor():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=my_endpoint_name,\n",
    "    sagemaker_session=my_session,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer\n",
    "    # ,\n",
    "    # component_name=None,\n",
    "    # **kwargs\n",
    ")\n",
    "\n",
    "# review\n",
    "print(my_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input payload can be created by following functions of the class [S3 Utilities](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html)\n",
    "\n",
    "1. **sagemaker.s3.s3_path_join(args)**: similarly to os.path.join()\n",
    "1. **sagemaker.s3.S3Downloader.read_file(s3_uri, sagemaker_session=None)**: returns the contents of an s3 uri file body as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file for inference\n",
    "my_infer_input_file = sagemaker.s3.s3_path_join(\n",
    "    my_input_data_infer_path,\n",
    "    my_input_data_file)\n",
    "\n",
    "# CSV data: string\n",
    "my_infer_input_str = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_infer_input_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# CSV data: byte stream object\n",
    "my_inference_input_obj = my_infer_input_str.encode()\n",
    "\n",
    "# review\n",
    "print('my_infer_input_file:')\n",
    "print(my_infer_input_file + '\\n')\n",
    "\n",
    "# review\n",
    "print('my_infer_input_str: ' + str(type(my_infer_input_str)))\n",
    "print('my_inference_input_obj: ' + str(type(my_inference_input_obj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().predict():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_forecast = my_predictor.predict(\n",
    "    data=my_inference_input_obj\n",
    "    # ,\n",
    "    # initial_args=None,\n",
    "    # target_model=None,\n",
    "    # target_variant=None,\n",
    "    # inference_id=None,\n",
    "    # custom_attributes=None,\n",
    "    # component_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review\n",
    "print('Output of real-time inference:')\n",
    "print(my_forecast)\n",
    "\n",
    "# review\n",
    "# Information on botocore.response.StreamingBody()\n",
    "# https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html\n",
    "print('\\nReal-time forecasts of time-series')\n",
    "print(my_forecast[0].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate it to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information sagemaker.transformer.Transformer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "#\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # strategy=None,\n",
    "    # assemble_with=None,\n",
    "    output_path=my_output_data_infer_path,\n",
    "    # output_kms_key=None,\n",
    "    accept=output_type,\n",
    "    # max_concurrent_transforms=None,\n",
    "    # max_payload=None,\n",
    "    # tags=None,\n",
    "    env=my_ENV,\n",
    "    # base_transform_job_name=None,\n",
    "    sagemaker_session=my_session\n",
    "    # ,\n",
    "    # volume_kms_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Batch-transform job input file is located in the S3 folder: {my_bucket}/{my_prefix}/input/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.inputs.TransformInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "my_transform_data_path = my_input_data_infer_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    compression_type=None,\n",
    "    # split_type=None,\n",
    "    # job_name=None,\n",
    "    # input_filter=None,\n",
    "    # output_filter=None, \n",
    "    # join_source=None,\n",
    "    # experiment_config=None,\n",
    "    # model_client_config=None,\n",
    "    # batch_data_capture_config=None,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# review\n",
    "print('Output of batch transform job:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the transform output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"{my_ENV['MODELOUTPUT']}.csv\" = \"forecast.csv\" | \"vcf_component.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"{my_ENV['MODELOUTPUT']}.json\" = \"forecast.json\" | \"vcf_component.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Delete the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a batch inference. IF you plan to review the trained or tuned model structure by using Transformer as demonstrated later, do NOT run the cell below. Otherwise, you can delete the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need more batch transform?\n",
    "more_batch_transform = True\n",
    "\n",
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "if not more_batch_transform:\n",
    "    my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model review by using Transformer (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Available LMDFM model output data items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"mean\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    mean_vec = LMDFM_obj.get_mean()  \n",
    "\n",
    "    mean_vec : pandas.Series, index (ts_list)\n",
    "        Sample mean vector of observed vector time-series\n",
    "            of data points in last learning window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"stdev\"**  \n",
    "   \n",
    "Data access method and data item(s):  \n",
    "\n",
    "    stdev_vec = LMDFM_obj.get_stdev()  \n",
    "    \n",
    "    stdev_vec : pandas.Series, index (ts_list)\n",
    "        Sample standard deviation vector of observed\n",
    "            vector time-series of data points in last\n",
    "            learning window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"factors\"**  \n",
    "    \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfm_factors = LMDFM_obj.get_factors()\n",
    "    \n",
    "    dfm_factors : pd.DataFrame,\n",
    "            index (factor_list), columns (asof_list)\n",
    "        Row time-series of common factor score column\n",
    "            of dynamic factor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vts_basecase\"**\n",
    "   \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    (vts_basecase, vts_basecase_comm, vts_basecase_idio\n",
    "        ) = LMDFM_obj.get_vts_basecase()\n",
    "\n",
    "    vts_basecase : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Standardized, serving as base-case, time-series\n",
    "            of observed vector time-series for dynamic\n",
    "            factor model learning and inference\n",
    "     \n",
    "    vts_basecase_comm : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Common components, represented by common factors,\n",
    "            of Standardized, or base-case, time-series\n",
    "            of observed vector time-series\n",
    "    \n",
    "    vts_basecase_idio : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Idiosyncratic components, not represented by\n",
    "            common factors, of Standardized, or base-\n",
    "            case, time-series of observed vector time-\n",
    "            series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"ldgs_basecase_collect\"**\n",
    "   \n",
    "Data access method and data item(s):  \n",
    "\n",
    "    ldgs_basecase_collect = (\n",
    "        LMDFM_obj.get_ldgs_basecase_collect())\n",
    "\n",
    "    ldgs_basecase_collect : dict, keys (\n",
    "                ldgs_order_1, ldgs_order_2, ...)\n",
    "            obj[key] = ldgs_basecase : dict,\n",
    "                keys (0,1,...,ldgs_order, 'asof')\n",
    "        dict-Type collection of dynamic factor\n",
    "            loadings matrixes of standardized\n",
    "            (or base-case) time-series of observed\n",
    "            vector time-series\n",
    "\n",
    "    ldgs_order : int\n",
    "        Order or maximum time-lag of dynamic\n",
    "            factor loadings coefficient matrix\n",
    "\n",
    "    ldgs_basecase : dict, keys (\n",
    "            0, 1, ..., ldgs_order, 'asof')\n",
    "        obj[key] : pd.DataFrame, index (ts_list),\n",
    "            columns (factor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfs_var_coef_collect\"**\n",
    "\n",
    "Data access method and data item(s):  \n",
    "\n",
    "    dfs_var_coef_collect = (\n",
    "        LMDFM_obj.get_dfs_var_coef_collect())\n",
    "    \n",
    "    dfs_var_coef_collect : dict, keys (\n",
    "                dfs_order_1, dfs_order_2, ...)\n",
    "            obj[key] = dfs_var_coef : dict,\n",
    "                keys (1,2,...,dfs_order, 'asof')\n",
    "            obj[0] = dict({})\n",
    "        dict-Type collection of vector auto-\n",
    "            regressive (VAR) coefficient matrix\n",
    "            of dynamic factor score time-series\n",
    "\n",
    "    dfs_order : int\n",
    "        Order or maximum time-lag of dynamic\n",
    "            factor scores vector autoregressive\n",
    "            (VAR) coefficient matrix\n",
    "\n",
    "    dfs_var_coef : dict, keys (\n",
    "            1, 2, ..., dfs_order, 'asof')\n",
    "        obj[key] : pd.DataFrame,\n",
    "            index / columns (factor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vts_common\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "     \n",
    "    vts_common = LMDFM_obj.get_vts_common()\n",
    "    \n",
    "    vts_common : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Common components of Standardized (base-case)\n",
    "            or Zero-mean or Original time-series of\n",
    "            observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vts_idiosync\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "     \n",
    "    vts_idiosync = LMDFM_obj.get_vts_idiosync()\n",
    "     \n",
    "    vts_idiosync : pd.DataFrame,\n",
    "            index (ts_list), columns (asof_list)\n",
    "        Idiosyncratic components of Standardized (base-\n",
    "            case) or Zero-mean or Original time-series\n",
    "            of observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfm_loadings_collect\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "\n",
    "    dfm_loadings_collect = (\n",
    "        LMDFM_obj.get_dfm_loadings_collect())\n",
    "  \n",
    "    dfm_loadings_collect : dict, keys (\n",
    "                ldgs_order_1, ldgs_order_2, ...)\n",
    "            obj[key] = dfm_loadings : dict,\n",
    "                keys (0,1,...,ldgs_order, 'asof')\n",
    "        dict-Type collection of dynamic loadings\n",
    "            matrixes of target_type time-series\n",
    "            of observed vector time-series\n",
    "\n",
    "    dfm_loadings : dict, keys (\n",
    "            0, 1, ..., ldgs_order, 'asof')\n",
    "        obj[key] : pd.DataFrame, index (ts_list),\n",
    "            columns (factor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfs_filter\"**  \n",
    "\n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_filter = LMDFM_obj.get_dfs_filter()\n",
    "    \n",
    "    dfs_filter : dict, keys (\n",
    "                0, 1, ..., var_order, 'asof')\n",
    "            obj[key] : pd.DataFrame,\n",
    "                index (factor_list), columns (ts_list)\n",
    "        Dynamic factor filter coefficient matrixes\n",
    "            generating dynamic factor score time-\n",
    "            series by observed vector time-series:\n",
    "            k-th matrix for contribution to factor\n",
    "            score f(t) from k-lag observed data\n",
    "            y(t-k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"var_coefs\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    var_left, var_right = LMDFM_obj.get_var_coefs()\n",
    "    \n",
    "    var_left : pd.DataFrame,\n",
    "            index (ts_list), columns (factor_list)\n",
    "        Left multiplier of DFM-based VAR model\n",
    "            coefficient matrixes of observed vector\n",
    "            time-series\n",
    "    \n",
    "    var_right : dict, keys (1, ..., var_order, 'asof')\n",
    "            obj[key] = dfs_filter[key] : pd.DataFrame,\n",
    "                index (factor_list), columns (ts_list)\n",
    "        Right multiplier of DFM-based VAR model\n",
    "            coefficient matrixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfs_serialcov\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_serialcov = LMDFM_obj.get_dfs_serialcov()\n",
    "    \n",
    "    dfs_serialcov : dict, keys ((-j, k), ..., 'asof')\n",
    "                -j, time lag, in time_lag_list\n",
    "                 k, sample lag, in sample_lag_list\n",
    "            obj[(-j, 0)] : pd.Series, index (factor_list)\n",
    "            obj[(-j, k)] : pd.DataFrame,\n",
    "                index / columns (factor_list), k >= 1\n",
    "        Estimated current (j = 0) and past (-j <= -1)\n",
    "            variance vector (k = 0) and k-lag auto-\n",
    "            covariance (serial-covariance) matrix\n",
    "            (k >= 1) of dynamic factor score time-series\n",
    "\n",
    "    time_lag_list : list, [(- var_order), ..., -1, 0]\n",
    "        List of time lags of estimated variance and\n",
    "            autocovariance data\n",
    "    \n",
    "    sample_lag_list : list, [0, 1, ..., var_order]\n",
    "        List of sample lags of estimated and forecasted\n",
    "            autocovariance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfs_prederr\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_prederr = LMDFM_obj.get_dfs_prederr()\n",
    "    \n",
    "    dfs_prederr : pd.DataFrame,\n",
    "            index (factor_list), columns (0, 'asof')\n",
    "        Estimated (as forecasted) variance vector\n",
    "            of error vector time-series in vector\n",
    "            autoregressive prediction of dynamic\n",
    "            factor scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"basecase_forecast\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_forecast, basecase_forecast = (\n",
    "        LMDFM_obj.get_basecase_forecast())\n",
    "\n",
    "    dfs_forecast : pd.DataFrame, index (factor_list),\n",
    "            columns (tsf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of dynamic\n",
    "            factor scores of observed vector time-\n",
    "            series (when forecast_type in ['DFM',\n",
    "            'FOMS'])\n",
    "    \n",
    "    basecase_forecast : pd.DataFrame, index (ts_list)\n",
    "            columns (tsf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of base-case\n",
    "            time-series of observed vector time-series,\n",
    "            with additional specification, forecast_type\n",
    "            ('DFM', 'MIX', 'FOMS' or 'VAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"basecase_response\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    basecase_response = (\n",
    "        LMDFM_obj.get_basecase_response())\n",
    "    \n",
    "    basecase_response : pd.DataFrame, index (ts_list)\n",
    "            columns (tsf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of base-\n",
    "            case response to exogenous shock vector\n",
    "            at latest time-stamp t = asof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"dfs_autocov\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_autocov = LMDFM_obj.get_dfs_autocov()\n",
    "    \n",
    "    dfs_autocov : dict, keys ((s, k), ..., 'asof')\n",
    "                s, forec step, in vcf_step_list\n",
    "                k, sample lag, in sample_lag_list\n",
    "            obj[(s, 0)] : pd.Series, index (factor_list)\n",
    "            obj[(s, k)] : pd.DataFrame,\n",
    "                index / columns (factor_list), k >= 1\n",
    "        Forecasted (s >= 1) variance vector (k = 0) and\n",
    "            k-lag autocovariance matrix (k >= 1) of dynamic\n",
    "            factor score time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"basecase_variance\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    (basecase_variance, basecase_var_comm,\n",
    "        basecase_var_idio) = (\n",
    "        LMDFM_obj.get_basecase_variance())\n",
    "    \n",
    "    basecase_variance : pd.DataFrame, index (ts_list),\n",
    "            columns (vcf_step_list + ['asof'])\n",
    "        Forecasted variances of individual base-case\n",
    "            time-series of observed vector time-series\n",
    "        Notes: basecase_variance = basecase_var_comm.add(\n",
    "            basecase_var_idio.loc[:, 0], axis='index')\n",
    "\n",
    "    basecase_var_comm : pd.DataFrame, index (ts_list),\n",
    "            columns (vcf_step_list + ['asof'])\n",
    "        Common components of forecasted variances of\n",
    "            individual base-case time-series of observed\n",
    "            vector time-series, forecasted by common\n",
    "            factors of observed time-series\n",
    "\n",
    "    basecase_var_idio : pd.DataFrame,\n",
    "            index (ts_list), columns (0, 'asof')\n",
    "        Idiocyncratic components of estimated (as\n",
    "            forecasted) variances of individual base-\n",
    "            case time-series of observed vector time-\n",
    "            series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"forecast\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    dfs_forecast, vts_forecast = LMDFM_obj.get_forecast()\n",
    "    \n",
    "    dfs_forecast : pd.DataFrame, index (factor_list),\n",
    "            columns (tsf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of dynamic\n",
    "            factor scores of observed vector time-\n",
    "            series (when forecast_type in ['DFM',\n",
    "            'FOMS'])\n",
    "     \n",
    "    vts_forecast : pd.DataFrame, index (ts_list)\n",
    "            columns (tsf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of\n",
    "            target_type time-series of observed\n",
    "            vector time-series, with two additional\n",
    "            specifications, forecast_type and\n",
    "            fwd_cumsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"response\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vts_response = LMDFM_obj.get_response()\n",
    "    \n",
    "    vts_response : pd.DataFrame, index (ts_list)\n",
    "            columns (tsf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of target_type\n",
    "            value of response to impulse or shock vector\n",
    "            at time t = asof, with one additional\n",
    "            specification, fwd_cumsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vcf_component\"**  \n",
    "   \n",
    "Data access method and data item(s):  \n",
    "   \n",
    "    dfm_loadings, dfs_variance, vts_var_idio = (\n",
    "        LMDFM_obj.get_vcf_component())\n",
    "  \n",
    "    dfm_loadings : dict, keys (\n",
    "                0, 1, ..., ldgs_order, 'asof')\n",
    "            obj[key] : pd.DataFrame, index (ts_list),\n",
    "                columns (factor_list)\n",
    "        Dynamic loadings matrix of time-lag j\n",
    "            (= 0,1, ...,ldgs_order) of target_type\n",
    "            time-series of observed vector time-\n",
    "            series\n",
    "    \n",
    "    dfs_variance : pd.DataFrame, index (factor_list),\n",
    "            columns (vcf_step_list + ['asof'])\n",
    "        Out-of-sample multi-step forecasts of variance vector\n",
    "            of dynamic factor score time-series of observed\n",
    "            vector time-series\n",
    "    \n",
    "    vts_var_idio : pd.DataFrame,\n",
    "            index (ts_list), columns (0, 'asof')\n",
    "        Idiosyncratic components of estimated\n",
    "            (as forecasted) variances of target_type\n",
    "            time-series of observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"vcf_matrix\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    vts_vcm_comm, vts_var_idio, vts_varcov = (\n",
    "        LMDFM_obj.get_vcf_matrix())\n",
    " \n",
    "    vts_vcm_comm : dict, keys (vcf_step_list + ['asof'])\n",
    "            obj[key] : pd.DataFrame,\n",
    "                index (ts_list), columns (ts_list)\n",
    "        Common component of forecasted variance-\n",
    "            covariance matrix of target_type time-\n",
    "            series of observed vector time-series\n",
    "    \n",
    "    vts_var_idio : pd.DataFrame,\n",
    "            index (ts_list), columns (0, 'asof')\n",
    "        Idiosyncratic components of estimated\n",
    "            (as forecasted) variances of target_type\n",
    "            time-series of observed vector time-series\n",
    "    \n",
    "    vts_varcov : dict, keys (vcf_step_list + ['asof'])\n",
    "            obj[key] : pd.DataFrame,\n",
    "                index (ts_list), columns (ts_list)\n",
    "        Forecasted variance-covariance matrix\n",
    "            of target_type time-series of observed\n",
    "            vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"indiv_variance\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    indiv_variance, indiv_var_comm, indiv_var_idio = (\n",
    "        LMDFM_obj.get_indiv_variance())\n",
    "    \n",
    "    indiv_variance : pd.DataFrame, index (ts_list),\n",
    "            columns (vcf_step_list + ['asof'])\n",
    "        Multi-step forecasts of variance of individual\n",
    "            target_type time-series of observed vector\n",
    "            time-series\n",
    "    \n",
    "    indiv_var_comm : pd.DataFrame, index (ts_list),\n",
    "            columns (vcf_step_list + ['asof'])\n",
    "        Common components of multi-step forecasts of variance\n",
    "            of individual target_type time-series of observed\n",
    "            vector time-series, forecasted by common dynamic\n",
    "            factors of observed time-series\n",
    "\n",
    "    indiv_var_idio : pd.DataFrame,\n",
    "            index (ts_list), columns (0, 'asof')\n",
    "        Idiocyncratic component of estimate (as forecasts)\n",
    "            of variance of individual target_type time-\n",
    "            series of observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"agg_variance\"**  \n",
    "  \n",
    "Data access method and data item(s):  \n",
    "    \n",
    "    agg_variance, agg_var_comm, agg_var_idio = (\n",
    "        LMDFM_obj.get_agg_variance())\n",
    "    \n",
    "    agg_variance : pd.Series, \n",
    "            index (vcf_step_list + ['asof'])\n",
    "        Multi-step forecasts of aggregate variance of all\n",
    "            target_type time-series of observed vector\n",
    "            time-series\n",
    "    \n",
    "    agg_var_comm : pd.Series,\n",
    "            index (vcf_step_list + ['asof'])\n",
    "        Common components of multi-step forecasts of\n",
    "            aggregate variance of all target_type time-\n",
    "            series of observed vector time-series,\n",
    "            forecasted by common dynamic factors of\n",
    "            observed time-series\n",
    "    \n",
    "    agg_var_idio : pd.Series, index (0, 'asof')\n",
    "        Idiosyncratic component of estimate (as forecasts)\n",
    "            of aggregate variance of all target_type time-\n",
    "            series of observed vector time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Select LMDFM model output data item for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained or tuned YWpcAR model structure can be reviewed item by item using Transformer with specific value of environment variable, my_ENV['MODELOUTPUT']  \n",
    "  \n",
    "Choices of value of the environment variable are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output_choice\n",
    "model_output_choice = dict({\n",
    "     1: 'mean',\n",
    "     2: 'stdev',\n",
    "     3: 'factors',\n",
    "     4: 'vts_basecase',\n",
    "     5: 'ldgs_basecase_collect',\n",
    "     6: 'dfs_var_coef_collect',\n",
    "     7: 'vts_common',\n",
    "     8: 'vts_idiosync',\n",
    "     9: 'dfm_loadings_collect',\n",
    "    10: 'dfs_filter',\n",
    "    11: 'var_coefs',\n",
    "    12: 'dfs_serialcov',\n",
    "    13: 'dfs_prederr',\n",
    "    14: 'basecase_forecast',\n",
    "    15: 'basecase_response',\n",
    "    16: 'dfs_autocov',\n",
    "    17: 'basecase_variance',\n",
    "    18: 'forecast',\n",
    "    19: 'response',\n",
    "    20: 'vcf_component',\n",
    "    21: 'vcf_matrix',\n",
    "    22: 'indiv_variance',\n",
    "    23: 'agg_variance'\n",
    "})\n",
    "\n",
    "# available choices for output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make any valid pair of choices as exemplified as in following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned for time-series forecast\n",
    "if tuning_plan in ['timeseries']:\n",
    "    model_output = model_output_choice[\n",
    "        14\n",
    "    ]\n",
    "\n",
    "# tuned for volatility forecast\n",
    "if tuning_plan in ['volatility']:\n",
    "    model_output = model_output_choice[\n",
    "        17\n",
    "    ]\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    1\n",
    "]\n",
    "\n",
    "# review\n",
    "print('model_output = ' + model_output)\n",
    "print('output_type = ' + output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Model structure review with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV variables\n",
    "my_ENV = dict({\n",
    "    'MODELOUTPUT': model_output})\n",
    "\n",
    "# sagemaker.transformer.Transformer()\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "#\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    # strategy=None,\n",
    "    # assemble_with=None,\n",
    "    output_path=my_output_data_infer_path,\n",
    "    # output_kms_key=None,\n",
    "    accept=output_type,\n",
    "    # max_concurrent_transforms=None,\n",
    "    # max_payload=None,\n",
    "    # tags=None,\n",
    "    env=my_ENV,\n",
    "    # base_transform_job_name=None,\n",
    "    sagemaker_session=my_session\n",
    "    # ,\n",
    "    # volume_kms_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.inputs.TransformInput()\n",
    "my_transform_data_path = my_input_data_infer_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'\n",
    "\n",
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    compression_type=None,\n",
    "    # split_type=None,\n",
    "    # job_name=None,\n",
    "    # input_filter=None,\n",
    "    # output_filter=None, \n",
    "    # join_source=None,\n",
    "    # experiment_config=None,\n",
    "    # model_client_config=None,\n",
    "    # batch_data_capture_config=None,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# display\n",
    "print('Selected output:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the selected output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"{my_ENV['MODELOUTPUT']}.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"{my_ENV['MODELOUTPUT']}.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Delete endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:  \n",
    "\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
