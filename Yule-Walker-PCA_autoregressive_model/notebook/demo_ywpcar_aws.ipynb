{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, deploy and review ML algorithm/model YWpcAR (Yule-Walker-PCA autoregressive model) from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of the algorithm\n",
    "  \n",
    "The Yule-Walker-PCA autoregressive model (YWpcAR) algorithm is developed to simultaneously analyze and forecast many time-series individually, assuming each time-series is influenced by evolution histories of a set of \"hidden components\" (resulted from PCA) affecting this specific time-series. Here PCA standards for \"principal components analysis\". Different time-series is influenced by different sets of hidden components (PCs).\n",
    "  \n",
    "By applying objective data-driven constraints, the YWpcAR algorithm can estimate the influences of longer histories of the PCs. The algorithm accommodates wider ranges of values of model learning/estimation parameters. The wider ranges can further enhance the power of machine learning.\n",
    "  \n",
    "Current version of the YWpcAR algorithm estimates: (a) autoregressive coefficients of time-series, (b) filter coefficients to generate unobserved component (sum of PCs), (c) time-series of the unobserved component, and (d) forecasts of the observed time-series. Other estimates will be added in the future releases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Academic publications on Yule-Walker autoregressive models (YWARs) and on principal component analysis (PCA)\n",
    "\n",
    "1. DW. R. Derryberry. 2014. \"Chapter 15. The Yule–Walker Equations and the Partial Autocorrelation Function”, in Basic Data Analysis for Time Series with R. John Wiley & Sons, Inc., 2014. https://doi.org/10.1002/9781118593233.\n",
    "\n",
    "1. I.T. Jolliffe. 2002. Principal Component Analysis, Second Edition. Springer, 2002. https://www.springer.com/gp/book/9780387954424."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methodology of introducing PCA into YW-AR modeling\n",
    "  \n",
    "1. Applying principal components analysis (PCA) to sample variance-autocovariance matrix, C, in Yule-Walker (YW) equation of autoregressive (AR) model.\n",
    "1. Replacing elements of the matrix C by PCA-based common components.\n",
    "1. Replacing elements of the matrix and vector in the YW equation by correspondent PCA-based common components of C.\n",
    "1. Estimating AR model coefficients by the PCA-based YW equation.\n",
    "1. In time-series forecasting with the YW-PCA AR (YWpcAR) model, replacing observed time-series data by unobserved components associated with the PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benefits of introducing PCA into YW-AR modeling\n",
    "  \n",
    "1. Noise reduction due to dimension reduction when the number of PCs, m, smaller than the autoregressive order, p.\n",
    "1. Avoiding over-fitting when estimating long-memory AR model of relatively larger value of order p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook\n",
    "\n",
    "This sample notebook shows you how to train, tune, deploy and understand a custom ML algorithm/model: [Yule-Walker-PCA Autoregressive model (YWpcAR)](https://aws.amazon.com/marketplace/pp/prodview-prndys7tr7go6?sr=0-1&ref_=beagle&applicationId=AWSMPContessa), guided by common practices to [Use Algorithm and Model Package Resources](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-buy.html).\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    1. or your AWS account has a subscription to [Yule-Walker-PCA Autoregressive model (YWpcAR)](https://aws.amazon.com/marketplace/pp/prodview-prndys7tr7go6?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "    1. [Subscription](#1.1.-Subscription)\n",
    "    1. [Prepare relevant environment](#1.2.-Prepare-relevant-environment)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "    1. [Dataset format expected by the algorithm](#2.1.-Dataset-format-expected-by-the-algorithm)\n",
    "    1. [Configure and visualize training dataset](#2.2.-Configure-and-visualize-training-dataset)\n",
    "    1. [Upload datasets to Amazon S3](#2.3.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3.-Train-a-machine-learning-model)\n",
    "    1. [Set hyperparameters](#3.1.-Set-hyperparameters)\n",
    "    1. [Train a model](#3.2.-Train-a-model)\n",
    "1. [Tune your model (optional)](#4.-Tune-your-model-(optional))\n",
    "    1. [Tuning Guidelines](#4.1.-Tuning-guidelines)\n",
    "    1. [Define Tuning configuration](#4.2.-Define-tuning-configuration)\n",
    "    1. [Run a model tuning job](#4.3.-Run-a-model-tuning-job)\n",
    "1. [Deploy model and verify results](#5.-Deploy-model-and-verify-results)\n",
    "    1. [Trained or tuned model](#5.1.-Trained-or-tuned-model)\n",
    "    1. [Deploy trained or tuned model](#5.2.-Deploy-trained-or-tuned-model)\n",
    "    1. [Create input payload](#5.3.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#5.4.-Perform-real-time-inference)\n",
    "1. [Perform Batch inference](#6.-Perform-batch-inference)\n",
    "    1. [Batch transform](#6.1.-Batch-transform)\n",
    "    1. [Delete the model](#6.2.-Delete-the-model)\n",
    "1. [Model review by using Transformer (optional)](#7.-Model-review-by-using-Transformer-(optional))\n",
    "    1. [AR model notations and equations](#7.1.-AR-(autoregressive)-model-notations-and-equations)\n",
    "    1. [Select model structure item for reviewed](#7.2.-Select-model-structure-item-for-review)\n",
    "    1. [Model structure review with Transformer](#7.3.-Model-structure-review-with-Transformer)\n",
    "1. [Clean-up](#8.-Clean-up)\n",
    "    1. [Delete endpoint and model](#8.1.-Delete-endpoint-and-model)\n",
    "    1. [Unsubscribe to the listing (optional)](#8.2.-Unsubscribe-to-the-listing-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage instructions\n",
    "\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sagemaker Notebook\n",
    "\n",
    "For readers who like to review how to use Sagemaker Notebook in general, following Sagemaker documentation pages are best resources.  \n",
    "    [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html)  \n",
    "    [Step 1: Create an Amazon SageMaker Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)  \n",
    "    [Step 2: Create a Jupyter Notebook](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-prepare.html)  \n",
    "    [Step 3: Download, Explore, and Transform a Dataset](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-preprocess-data.html)  \n",
    "    [Step 4: Train a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-train-model.html)  \n",
    "    [Step 5: Deploy the Model to Amazon EC2](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-model-deployment.html)  \n",
    "    [Step 6: Evaluate the Model](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-test-model.html)  \n",
    "    [Step 7: Clean Up](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "\n",
    "1. Open the algorithm listing page, [Yule-Walker-PCA Autoregressive model (YWpcAR)](https://aws.amazon.com/marketplace/pp/prodview-prndys7tr7go6?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your valid algorithm ARN\n",
    "# my_algorithm_arn = 'arn:aws:sagemaker:{region}:123456789012:algorithm/{ywpcar_algorithm}'\n",
    "my_algorithm_arn = 'arn:aws:sagemaker:{}:{}:algorithm/{}'.format(\n",
    "    'your_region', 'your_aws_account_number', 'your_ywpcar_algorithm_label')\n",
    "my_prefix = 'ywpcar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Prepare relevant environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "# remind\n",
    "print('Wait for Sagemaker values assigned to TWO important variables: my_bucket and my_role.\\n')\n",
    "\n",
    "# sagemaker session\n",
    "my_session = sagemaker.session.Session()\n",
    "\n",
    "# sagemaker attributes\n",
    "my_bucket = my_session.default_bucket()\n",
    "my_role = sagemaker.session.get_execution_role()\n",
    "\n",
    "# review\n",
    "print('my_bucket = {}'.format(my_bucket))\n",
    "print('my_role = {}'.format(my_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this Sagemaker machine learning ('ml') notebook example, following S3 folders are expected to be in place:\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. {my_bucket}/{my_prefix}/model/\n",
    "1. {my_bucket}/{my_prefix}/output/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 paths\n",
    "my_training_input_data_path = 's3://{}/{}/input/data/train'.format(my_bucket, my_prefix)\n",
    "my_inference_input_path = 's3://{}/{}/input/data/inference'.format(my_bucket, my_prefix)\n",
    "my_model_data_path = 's3://{}/{}/model'.format(my_bucket, my_prefix)\n",
    "my_inference_result_path = 's3://{}/{}/output/data/inference'.format(my_bucket, my_prefix)\n",
    "\n",
    "# ywpcar Docker container training channel\n",
    "training_input_channel = 'train'\n",
    "\n",
    "# aws computing instance type: 'ml.m5.xlarge'\n",
    "my_EC2 = 'ml.m5.xlarge'\n",
    "\n",
    "# input CSV data file name\n",
    "my_input_data_file = 'Weekly_VTS_6Yr.csv'\n",
    "\n",
    "# information available model and endpoint\n",
    "my_model_data = str()  # to be assigned / defined\n",
    "my_model_name = str()  # to be assigned / defined \n",
    "my_endpoint_name = 'my-endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are revisiting this demo notebook, and your model training job and/or your hyperparameter tuning job (to be defined later) were already run at least once, you can copy the resulted Sagemaker string values of your trained model data path and/or your tuned model data path to the variables, my_trained_model_data and/or my_tuned_model_data, in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model placeholder\n",
    "# my_trained_model_data = str()\n",
    "my_trained_model_data = str()\n",
    "my_trained_model_name = 'my-trained-model'\n",
    "\n",
    "# AVAILABLE trained model\n",
    "# IF model is trained and not to be trained again, copy-paste or type the full model data path for my_trained_model_data\n",
    "# my_trained_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "my_trained_model_data = ''\n",
    "\n",
    "# review\n",
    "print('Model data of trained model:')\n",
    "print(my_trained_model_data)\n",
    "print('Name of trained model:')\n",
    "print(my_trained_model_name)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# tuned model placeholder\n",
    "# my_tuned_model_data = str()\n",
    "my_tuned_model_data = str()\n",
    "my_tuned_model_name = 'my-tuned-model'\n",
    "\n",
    "# AVAILABLE tuned model\n",
    "# IF model is tuned and not to be tuned again, copy-paste or type the full model data path for my_tuned_model_data\n",
    "# my_tuned_model_data = '{my_bucket}/{my_prefix}/model/{some_path}/model.tar.gz'\n",
    "my_tuned_model_data = ''\n",
    "\n",
    "# review\n",
    "print('\\nModel data of tuned model:')\n",
    "print(my_tuned_model_data)\n",
    "print('Name of tuned model:')\n",
    "print(my_tuned_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The YWpcAR (Yule-Walker-PCA autoregressive model) algorithm takes, as input data,\n",
    "multiple time-series data contained in a CSV (comma separated value) data table, in a format of a CSV text-string or a CSV text-file.\n",
    "\n",
    "Each row of the data table is for values of an individual time-series (TS). Row header is the label or symbol of the time-series.\n",
    "Each column is for values of all time-series at a specific moment in time. Column header is the time-index or time-stamp of the moment.\n",
    "The first data column is for the earliest time and the last column for the most recent time.\n",
    "Therefore, the first row of the CSV data table is \"Label/Symbol/Description, earliest time-stamp, next time-stamp, ..., most recent time-stamp\".\n",
    "The first column of the CSV table is \"Label/Symbol/Description, label of 1st TS, label of 2nd TS, ..., label of last TS\".\n",
    "The current version of YWpcAR requires equally spaced time-stamps.\n",
    "\n",
    "One of the simplest methods to generate such a CSV text-file is to save a Microsoft Excel spreadsheet as (into) a CSV file.\n",
    "\n",
    "You can also find more information about dataset format in **Usage Information** section of \n",
    "[Yule-Walker-PCA Autoregressive model (YWpcAR)](https://aws.amazon.com/marketplace/pp/prodview-prndys7tr7go6?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Configure and visualize training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [sample data](https://github.com/i4cast/aws/blob/main/Yule-Walker-PCA_autoregressive_model/input/Weekly_VTS_6Yr.csv) provided with this product/example is six-year weekly (logarithmic) performances of mutual funds traded in the U.S. invested in equities, fixed income, and commodities. Each row is of an individual mutual fund. Each column is of a specific calendar week in history. The last week (the last column) was the week with a time-stamp as \"2021-12-31\". Following simple steps you can upload this sample data to your S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the sample dataset from https://github.com/i4cast/aws/blob/main/Yule-Walker-PCA_autoregressive_model/input/Weekly_VTS_6Yr.csv, and then upload the dataset to\n",
    "\n",
    "1. {my_bucket}/{my_prefix}/input/data/train/ for training\n",
    "1. {my_bucket}/{my_prefix}/input/data/inference/ for inference\n",
    "\n",
    "following simple steps can be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open webpage https://github.com/i4cast/aws/blob/main/Yule-Walker-PCA_autoregressive_model/input/Weekly_VTS_6Yr.csv\n",
    "1. Click [Raw] option located at top right of the data table\n",
    "1. In the Raw data window, right click [Save as]\n",
    "1. Set local file folder and file name in the \"Save As\" window, then click [Save]\n",
    "\n",
    "1. Open AWS S3 Console\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/train/\n",
    "1. Upload the saved local data file to your AWS S3 folder\n",
    "1. Go to S3 folder: {my_bucket}/{my_prefix}/input/data/inference/\n",
    "1. Upload the saved local data file to your AWS S3 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about dataset format in **Hyperparameters** section of [Yule-Walker-PCA Autoregressive model (YWpcAR)](https://aws.amazon.com/marketplace/pp/prodview-prndys7tr7go6?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "# all individual elements must be individual strings\n",
    "my_hyperparam = {\n",
    "    'len_learn_window': '52',\n",
    "    'ar_order': '13',\n",
    "    'num_pcs': '2',\n",
    "    'max_forecast_step': '13',\n",
    "    'target_type': 'Original',\n",
    "    'fwd_cumsum': 'True',\n",
    "    'alt_ar_order': {},\n",
    "    'alt_num_pcs': {},\n",
    "    'num_forecasts': '13',\n",
    "    'half_life_list': ['13', '26', '52'],\n",
    "    'eval_metric_list': ['projection_coefficient']\n",
    "}\n",
    "\n",
    "# define metrics\n",
    "my_metrics = list()\n",
    "for metric_name in my_hyperparam['eval_metric_list']:\n",
    "    for half_life in my_hyperparam['half_life_list']:\n",
    "        my_metrics.append(dict({\n",
    "            'Name': '{}_#_{}'.format(metric_name, half_life),\n",
    "            'Regex': '{}_#_{}=(.*?);'.format(metric_name, half_life)\n",
    "        }))\n",
    "\n",
    "# review\n",
    "print('Hyperparameters: my_hyperparam =')\n",
    "print(my_hyperparam)\n",
    "\n",
    "# review\n",
    "print('\\nEvaluation metrics: my_metrics =')\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple time-series, the values of two parameters, ar_order and num_pcs, set above are default values applied to all time-series. You can set different values of the two parameters to be applied to some or all time-series one by one. Following two variables, alt_ar_order and alt_num_pcs, are to be used to set \"time-series specific values\" of ar_order and num_pcs.  \n",
    "  \n",
    "To set specific values of ar_order and/or num_pcs for some or all time-series one by one in the following cell,\n",
    "1. set indicator alt_aro_npc to True,\n",
    "1. specify key-value pairs in variable alt_ar_order and/or alt_num_pcs,\n",
    "1. update my_hyperparam by the newly specified alt_ar_order and/or alt_num_pcs, and then\n",
    "1. review the values of the updated my_hyperparam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-series specific ar_order and num_pcs ?\n",
    "# alt_aro_npc = True | False\n",
    "alt_aro_npc = False\n",
    "\n",
    "# time-series specific param holder\n",
    "alt_ar_order = dict({\n",
    "    'SPY': '15', 'DIA': '14', 'QQQ': '12'\n",
    "})\n",
    "alt_num_pcs = dict({\n",
    "    'SPY': '5', 'DIA': '4', 'QQQ': '3'\n",
    "})\n",
    "\n",
    "# hyperparameters with time-series specific ar_order and num_pcs\n",
    "if alt_aro_npc:\n",
    "    my_hyperparam['alt_ar_order'] = alt_ar_order.copy()\n",
    "    my_hyperparam['alt_num_pcs'] = alt_num_pcs.copy()\n",
    "\n",
    "# review\n",
    "print('Hyperparameters: my_hyperparam =')\n",
    "print(my_hyperparam)\n",
    "\n",
    "# review\n",
    "print('\\nEvaluation metrics: my_metrics =')\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an estimator object for running a training job\n",
    "# Information on sagemaker.algorithm.AlgorithmEstimator():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "my_estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=my_algorithm_arn,\n",
    "    role=my_role,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    input_mode='File',\n",
    "    output_path=my_model_data_path,\n",
    "    base_job_name='my-training-job',\n",
    "    sagemaker_session=my_session,\n",
    "    hyperparameters=my_hyperparam,\n",
    "    model_channel_name='model',\n",
    "    metric_definitions=my_metrics\n",
    ")\n",
    "\n",
    "# Information on sagemaker.inputs.TrainingInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "my_training_input = dict({\n",
    "    training_input_channel:\n",
    "        sagemaker.inputs.TrainingInput(\n",
    "            s3_data=my_training_input_data_path,\n",
    "            content_type='text/csv',\n",
    "            s3_data_type='S3Prefix',\n",
    "            input_mode='File')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_training_job, to TRUE, in order to\n",
    "1. run YWpcAR model training job\n",
    "1. save model artifacts of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training_job = True | False\n",
    "run_training_job = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_training_job above to TRUE and running model training job in the cell below, you can re-set run_training_job indicator back to FALSE in order to avoid accidentally running model training job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then train the model and save the result\n",
    "if run_training_job and (len(my_tuned_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Train the model. Wait for training job completes with information:')\n",
    "    print('Model data of trained model\\n')\n",
    "    \n",
    "    # Information on sagemaker.algorithm.AlgorithmEstimator().fit()\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
    "    my_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All')\n",
    "    \n",
    "    # model data information\n",
    "    my_trained_model_data = my_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of trained model:')\n",
    "    print(my_trained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information how to visualize metrics during the process, see [Easily monitor and visualize metrics while training models on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/).\n",
    "\n",
    "You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune your model (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Tuning guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and/or forecasting different sets of multiple time-series require different values of hyperparameters: len_learn_window, ar_order, and num_pcs.\n",
    "\n",
    "Therefore, decisions on specific (integer) values of these hyperparameters need to be made before making meaningful training and inference. There are a variety of commonly practiced methods to estimate the appropriate hyperparameter values. When using AWS Sagemaker, it is natural to use Sagemaker's HyperparameterTuner class to search for appropriate hyperparameter values which result in better forecasts.\n",
    "\n",
    "For information about Automatic model tuning, also see [Perform Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Define tuning configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible ranges of appropriate hyperparameter values depend on specific dataset at hand. For the sample dataset used in this example, a set of reasonable ranges of hyperparameter values are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.IntegerParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "int_hyperpar_range_example = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=52, max_value=157, scaling_type='Auto'),\n",
    "    'ar_order':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=52, scaling_type='Auto'),\n",
    "    'num_pcs':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=1, max_value=20, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural seasonality of time-series and some \"rule of thumb for choices\" may be utilized to focus on a few reasonable values within reasonable ranges. Following example can be used for a simpler model tuning.\n",
    "\n",
    "For general information about AWS SageMaker Hyperparameter Tuning, referred to [How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) and [Define Hyperparameter Ranges](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.parameter.CategoricalParameter():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
    "my_hyperparam_range = dict({\n",
    "    'len_learn_window':\n",
    "        sagemaker.parameter.CategoricalParameter(['52', '157']),\n",
    "    'ar_order':\n",
    "        sagemaker.parameter.CategoricalParameter(['13', '52']),\n",
    "    'num_pcs':\n",
    "        sagemaker.parameter.IntegerParameter(\n",
    "        min_value=2, max_value=10, scaling_type='Auto')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different inference applications need to use different metrics to measure relevant goodness of fit. In this example, we try to forecast future performances of U.S. mutual funds. Proportionalities (a quantifiable version of similarity) between forecasted and realized absolute performances can serve as a useful measure of goodness of fit.\n",
    "\n",
    "If we regard a set of forecasted or realized absolute performances as a multi-dimensional vector, projection of one vector (e.g. forecasted) onto the other (e.g. realized) is a measure of \"proportionality (or similarity) between the two sets of absolute performances\".\n",
    "\n",
    "Therefore, we use the \"projection coefficient\" as the objective metric for tuning the hyperparameters.\n",
    "\n",
    "For general information about AWS SageMaker Metrics, referred to [Define Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available choices for objective tuning metric\n",
    "print('Available model evaulation metrics:')\n",
    "print(my_metrics)\n",
    "\n",
    "# name of objective tuning metric\n",
    "my_objective_metric = my_metrics[-1]['Name']\n",
    "\n",
    "# review\n",
    "print('\\nObjective tuning metric')\n",
    "print(my_objective_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, minimizing error and/or maximizing similarity are desirable tuning directions. Therefore, we will maximize our objective metric, projection coefficient, in this hyperparameter tuning example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direction of hyperparameter optimization\n",
    "my_objective_type = 'Maximize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Run a model tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up hyperparameter tuning job\n",
    "# Information on sagemaker.tuner.HyperparameterTuner():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "my_tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=my_estimator,\n",
    "    objective_metric_name=my_objective_metric,\n",
    "    hyperparameter_ranges=my_hyperparam_range,\n",
    "    objective_type=my_objective_type,\n",
    "    max_jobs=1,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='my-tuning-job',\n",
    "    early_stopping_type='Auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set the boolean indicator, run_tuning_job, to TRUE, in order to\n",
    "1. run hyperparameter optimization job\n",
    "1. save optimal model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tuning_job = True | False\n",
    "run_tuning_job = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During waiting time after setting indicator run_tuning_job above to TRUE and running hyperparameter tuning job in the cell below, you can re-set run_tuning_job indicator back to FALSE in order to avoid accidentally running hyperparameter tuning job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRUE then optimize model and save the result\n",
    "if run_tuning_job and (len(my_tuned_model_data) < 0.5):\n",
    "    \n",
    "    # remind\n",
    "    print('Tune the model. Wait for tuning job completes with information:')\n",
    "    print('Model data of tuned model\\n')\n",
    "    \n",
    "    # tuning and waiting\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().fit():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuner.fit(\n",
    "        inputs=my_training_input)\n",
    "    my_tuner.wait()\n",
    "    \n",
    "    # get tuned model and artfacts of the tuned model\n",
    "    # Information on sagemaker.tuner.HyperparameterTuner().best_estimator():\n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    my_tuned_estimator = my_tuner.best_estimator()\n",
    "    my_tuned_estimator.fit(\n",
    "        inputs=my_training_input,\n",
    "        wait=True,\n",
    "        logs='All')\n",
    "    \n",
    "    # optimized hyperparameters\n",
    "    my_tuned_hyperparam = my_tuned_estimator.hyperparameters()\n",
    "    \n",
    "    # optimal model artfacts\n",
    "    my_tuned_model_data = my_tuned_estimator.model_data\n",
    "    \n",
    "    # review\n",
    "    print('\\nTuned hyperparameters:')\n",
    "    print(my_tuned_hyperparam)\n",
    "    \n",
    "    # review\n",
    "    print('\\nModel data of tuned model:')\n",
    "    print(my_tuned_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recommended by AWS Sagemaker Team, once you have completed a tuning job, (or even while the job is still running) you can [clone and use this notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to analyze the results to understand how each hyperparameter effects the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available trained model\n",
    "if len(my_trained_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_trained_model_data\n",
    "    my_model_name = my_trained_model_name\n",
    "\n",
    "# available tuned model\n",
    "if len(my_tuned_model_data) > len('s3://.tar.gz'):\n",
    "    my_model_data = my_tuned_model_data\n",
    "    my_model_name = my_tuned_model_name\n",
    "\n",
    "# Information on sagemaker.model.ModelPackage():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_model = sagemaker.model.ModelPackage(\n",
    "    role=my_role,\n",
    "    model_data=my_model_data,\n",
    "    algorithm_arn=my_algorithm_arn,\n",
    "    name=my_model_name\n",
    ")\n",
    "\n",
    "# review\n",
    "print('Name of model:')\n",
    "print(my_model_name)\n",
    "\n",
    "# review\n",
    "print('\\nArtifacts of model:')\n",
    "print(my_model_data)\n",
    "\n",
    "# review\n",
    "print('\\nModel pacakge')\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Deploy trained or tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Start endpoint for inference. Wait for endpoint becomes ready')\n",
    "\n",
    "# Information on sagemaker.model.Model().deploy():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "my_endpoint = my_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    endpoint_name=my_endpoint_name\n",
    ")\n",
    "\n",
    "# review\n",
    "print('\\nSagemaker endpoint, ' + my_endpoint_name + ', is now ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.serializers.IdentitySerializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html\n",
    "my_serializer = sagemaker.serializers.IdentitySerializer()\n",
    "\n",
    "# Information on sagemaker.deserializers.StreamDeserializer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html\n",
    "my_deserializer = sagemaker.deserializers.StreamDeserializer()\n",
    "\n",
    "# Predictor\n",
    "# Information on sagemaker.predictor.Predictor():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=my_endpoint_name,\n",
    "    sagemaker_session=my_session,\n",
    "    serializer=my_serializer,\n",
    "    deserializer=my_deserializer\n",
    ")\n",
    "\n",
    "# review\n",
    "print(my_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input payload can be created by following functions of the class [S3 Utilities](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html)\n",
    "\n",
    "1. **sagemaker.s3.s3_path_join(*args)**: similarly to os.path.join()\n",
    "1. **sagemaker.s3.S3Downloader.read_file(s3_uri, sagemaker_session=None)**: returns the contents of an s3 uri file body as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file for inference\n",
    "my_infer_input_file = sagemaker.s3.s3_path_join(\n",
    "    my_inference_input_path,\n",
    "    my_input_data_file)\n",
    "\n",
    "# CSV data: string\n",
    "my_infer_input_str = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_infer_input_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# CSV data: byte stream object\n",
    "my_inference_input_obj = my_infer_input_str.encode()\n",
    "\n",
    "# review\n",
    "print('my_infer_input_file:')\n",
    "print(my_infer_input_file + '\\n')\n",
    "\n",
    "# review\n",
    "print('my_infer_input_str: ' + str(type(my_infer_input_str)))\n",
    "print('my_inference_input_obj: ' + str(type(my_inference_input_obj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().predict():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_forecast = my_predictor.predict(\n",
    "    data=my_inference_input_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review\n",
    "print('Output of real-time inference:')\n",
    "print(my_forecast)\n",
    "\n",
    "# review\n",
    "# Information on botocore.response.StreamingBody()\n",
    "# https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html\n",
    "print('\\nReal-time forecasts of time-series')\n",
    "print(my_forecast[0].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate it to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default inference ENV variables\n",
    "my_ENV = dict({\n",
    "    'TRAINTYPE': 'ContinuousTraining',\n",
    "    'MODELOUTPUT': 'forecast'\n",
    "})\n",
    "\n",
    "# available output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    2\n",
    "]\n",
    "\n",
    "# Information sagemaker.transformer.Transformer():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    output_path=my_inference_result_path,\n",
    "    accept=output_type,\n",
    "    env=my_ENV,\n",
    "    sagemaker_session=my_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Batch-transform job input file is located in the S3 folder: {my_bucket}/{my_prefix}/input/data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.inputs.TransformInput():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "my_transform_data_path = my_inference_input_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# Information on sagemaker.transformer.Transformer().transform():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    logs=True\n",
    ")\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# review\n",
    "print('Output of batch transform job:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the transform output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"forecast.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"forecast.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Delete the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a batch inference. IF you plan to review the trained or tuned model structure by using Transformer as demonstrated later, do NOT run the cell below. Otherwise, you can delete the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need more batch transform?\n",
    "more_batch_transform = True\n",
    "\n",
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "if not more_batch_transform:\n",
    "    my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model review by using Transformer (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. AR (autoregressive) model notations and equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acronyms**  \n",
    "  \n",
    "AR : univariate autoregressive model of a time-series  \n",
    "YW : Yule-Walker equation of AR model  \n",
    "PCA : principal components analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notations**  \n",
    "  \n",
    "$y(t)$ : observed data time-series with time index $t$  \n",
    "$z(t)$ : unobserved component (determined by PCA on YW) time-series of data $y(t)$  \n",
    "$e(t)$ : random errors  \n",
    "$b(j)$ : coefficients of filter generating unobserved components  \n",
    "$a(k)$ : autoregressive coefficients of AR model  \n",
    "  \n",
    "**Assuming parameter values**  \n",
    "  \n",
    "$t = 0, 1, 2, ..., T$  \n",
    "$T$ : last time stamp  \n",
    "$j = 0, 1, 2, ..., p$  \n",
    "$k = 1, 2, ..., p$  \n",
    "$p$ : autoregressive order  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoregressive coefficients**  \n",
    "  \n",
    "$a(k)$ are estimated by  \n",
    "  \n",
    "$y(t) = a(1) y(t-1) + a(2) y(t-2) + ... + a(p) y(t-p) + e(t)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter coefficients**  \n",
    "  \n",
    "$b(k)$ are estimated by  \n",
    "  \n",
    "$z(t) = b(0) y(t) + b(1) y(t-1) + ... + b(p) y(t-p)$  \n",
    "$y(t) = z(t) + e(t)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Select model structure item for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained or tuned YWpcAR model structure can be reviewed item by item using Transformer with specific values of two environment variables: (1) TRAINTYPE and (2) MODELOUTPUT  \n",
    "\n",
    "Choices of values of the two environment variables are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available choices for TRAINTYPE\n",
    "train_type_choice = dict({\n",
    "    1: 'StaticTraining',     # for trained model\n",
    "    2: 'ContinuousTraining'  # for re-trained model\n",
    "})\n",
    "\n",
    "# available choices for MODELOUTPUT\n",
    "model_output_choice = dict({\n",
    "    1: 'mean',\n",
    "    2: 'stdev',\n",
    "    3: 'ARcoefs',\n",
    "    4: 'filter',\n",
    "    5: 'unobs'\n",
    "})\n",
    "\n",
    "# available choices for output type\n",
    "output_type_choice = dict({\n",
    "    1: 'text/csv',\n",
    "    2: 'application/json'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make any valid pair of choices as exemplified as in following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice for TRAINTYPE (an integer between 1 and 2)\n",
    "training_type = train_type_choice[\n",
    "    2\n",
    "]\n",
    "\n",
    "# choice for MODELOUTPUT (an integer between 1 and 11)\n",
    "model_output = model_output_choice[\n",
    "    3\n",
    "]\n",
    "\n",
    "# output type\n",
    "output_type = output_type_choice[\n",
    "    2\n",
    "]\n",
    "\n",
    "# review\n",
    "print('training_type = ' + training_type)\n",
    "print('model_output = ' + model_output)\n",
    "print('output_type = ' + output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Model structure review with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV variables\n",
    "my_ENV = dict({\n",
    "    'TRAINTYPE': training_type,\n",
    "    'MODELOUTPUT': model_output})\n",
    "\n",
    "# sagemaker.transformer.Transformer()\n",
    "my_transformer = sagemaker.transformer.Transformer(\n",
    "    model_name=my_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=my_EC2,\n",
    "    output_path=my_inference_result_path,\n",
    "    accept=output_type,\n",
    "    env=my_ENV,\n",
    "    sagemaker_session=my_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.inputs.TransformInput()\n",
    "my_transform_data_path = my_inference_input_path\n",
    "my_transform_data_type = 'S3Prefix'\n",
    "my_transform_content_type = 'text/csv'\n",
    "\n",
    "# remind\n",
    "print('Run batch transform. Wait for transform job completes with information:')\n",
    "print('Batch transform output path')\n",
    "\n",
    "# sagemaker.transformer.Transformer()\n",
    "my_transformer.transform(\n",
    "    data=my_transform_data_path,\n",
    "    data_type=my_transform_data_type,\n",
    "    content_type=my_transform_content_type,\n",
    "    logs=True)\n",
    "\n",
    "# wait\n",
    "my_transformer.wait()\n",
    "\n",
    "# output is available on following path\n",
    "my_transform_output_path = my_transformer.output_path\n",
    "print('Batch transform output path:')\n",
    "print(my_transform_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display and review output generated by the batch transform job available in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output file name = {input_data_file}.csv.out\n",
    "my_transform_output_file = my_input_data_file + '.out'\n",
    "\n",
    "# data file for inference\n",
    "my_inference_file = sagemaker.s3.s3_path_join(\n",
    "    my_transform_output_path,\n",
    "    my_transform_output_file)\n",
    "\n",
    "# CSV data string\n",
    "my_inference = sagemaker.s3.S3Downloader.read_file(\n",
    "    my_inference_file, \n",
    "    sagemaker_session=my_session)\n",
    "\n",
    "# display\n",
    "print('Selected output:\\n')\n",
    "print(my_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the selected output file name to keep the file from being overwritten.\n",
    "\n",
    "Open AWS S3 Console, go to the batch transform output path shown above, re-name the file \"{inference_input_data_file_name}.csv.out\" to\n",
    "1. \"{model_output}_by_{training_type}.csv\", if accept = output_type = 'text/csv', or\n",
    "1. \"{model_output}_by_{training_type}.json\", if accept = output_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Delete endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.predictor.Predictor().delete_endpoint():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "my_predictor.delete_endpoint(\n",
    "    delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on sagemaker.session.Session().delete_model():\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "my_session.delete_model(my_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:  \n",
    "\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
